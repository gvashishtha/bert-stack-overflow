435714,If I deploy my web application to Windows Azure  do I need a traditional host? <p>I just started to read about this new technology... </p>  <p>Does someone have some knowledge about it? </p>,azure-web-app-service
34032714,"How to get all valid fields for WIQL query using TFS API C#? <p>I found this:</p>  <p><a href=\https://msdn.microsoft.com/en-us/library/ms244668(v=vs.90).aspx\"" rel=\""nofollow\"">https://msdn.microsoft.com/en-us/library/ms244668(v=vs.90).aspx</a></p>  <p>But I think that may be in regards to the database copy or something?</p>  <p>I just need to know if there is a way I can get a list of all the valid fields that can go into a SELECT clause in a WIQL like :</p>  <pre><code>SELECT [System.Id] [System.WorkItemType] FROM WorkItem </code></pre>  <p>I don't think WorkItemType is valid  when I tried outputting out it threw an exception:</p>  <pre><code>Console.WriteLine(\""ID: {0}\""  workItem.Id); Console.WriteLine(\""Work Item Type: {0}\""  workItem.WorkItemType); </code></pre>""",azure-devops
47086247,"Azure Function Func.exe \host start\"" with multiple directories <p>Is it possible for a single func.exe to host multiple function projects?</p>""",azure-functions
51546073,"How to run Azure CLI commands using python? <p>I want to use Azure CLI to get the list of all the VMs in my resource group. But I want to implement the same using a python script. </p>  <p>For example  I will use the following command in Azure CLI to list the VMs in my resource group:</p>  <p>\ az vm list -g MyResourceGroup \""</p>  <p>But  I want the python script to do the same  where I just have to incorporate the CLI command in the python program.</p>""",azure-virtual-machine
55340614,"IIS Application Request Routing: Fails to proxy website on JBoss <p>I configured an ARR on Azreu AppService  to reverse proxy a java website on JBoss. Although my rule works with a specific website  it fails with the one I want to expose.</p>  <p>My applicationHost.xdt looks like:</p>  <pre><code>&lt;?xml version=\1.0\""?&gt; &lt;configuration xmlns:xdt=\""http://schemas.microsoft.com/XML-Document-Transform\""&gt; &lt;system.webServer&gt;     &lt;proxy xdt:Transform=\""InsertIfMissing\"" enabled=\""true\"" preserveHostHeader=\""false\"" reverseRewriteHostInResponseHeaders=\""true\"" /&gt; &lt;/system.webServer&gt; &lt;/configuration&gt; </code></pre>  <p>My web.config looks like:</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt;   &lt;configuration&gt;       &lt;system.webServer&gt;         &lt;httpErrors errorMode=\""Detailed\"" /&gt;         &lt;rewrite&gt;             &lt;rules&gt;                 &lt;rule name=\""Proxy\"" stopProcessing=\""false\""&gt;                       &lt;match url=\"".*\"" /&gt;                       &lt;action type=\""Rewrite\"" url=\""http://10.0.0.1/{R:0}\"" /&gt;                   &lt;/rule&gt;               &lt;/rules&gt;         &lt;/rewrite&gt;     &lt;/system.webServer&gt; &lt;/configuration&gt; </code></pre>  <p>Every time I try to access the default webpage  after the html is loaded  all the dependecies (js  css  images) return the html of the default page (html). The images and dependencies don't require authentication  as I can be access them by calling the direct url in an InPrivate browser. I guess JBoss redirect every call to the default page  as something is missing  or some security options applied in JBoss.</p>  <ul> <li>Is there some headers/methods/cookies that doesn't work with ARR ?</li> <li>Can we proxy any webserver  or some have some limitations/constraints/security?</li> </ul>  <p>Unfortunately I don't have access to the remote JBoss logs/configuration. Trying to blind debug it. Help would be much appreciated.</p>""",azure-web-app-service
53686525,How can I find out what image was used to build an AzureVM? <p>When building a new VM on Azure  you have many different OS options available to choose from.  How can I find out which option was used for an existing VM?</p>,azure-virtual-machine
53950497,"Correctly packaging CSS files for deployment to Azure CDN as part of Azure DevOps extension <p>I'm developing an Azure DevOps extension  which displays the a summary of work items for the current Sprint for printing.</p>  <p>I am failing to get static CSS files to publish correctly.</p>  <p>I have the following configured in the manifest.json in the files section:</p>  <pre><code>    {         \path\"": \""css/print.css\""          \""contentType\"": \""text/css\""          \""addressable\"": true     }      {         \""path\"": \""css/screen.css\""          \""contentType\"": \""text/css\""          \""addressable\"": true     }  </code></pre>  <p>The structure of the project is:</p>  <pre><code>css/screen.css css/print.css board-cards.html vss-extension.json </code></pre>  <p>Reading this documentation: <a href=\""https://docs.microsoft.com/en-us/azure/devops/extend/develop/static-content\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/extend/develop/static-content</a> indicates that the static content <em>should</em> be published to: <a href=\""https://publisher.gallery.vsassets.io\"" rel=\""nofollow noreferrer\"">https://publisher.gallery.vsassets.io</a>.</p>  <p>When debugging - the following two 404's appear in the network log:</p>  <p><a href=\""https://publisher.gallerycdn.vsassets.io/css/print.css\"" rel=\""nofollow noreferrer\"">https://publisher.gallerycdn.vsassets.io/css/print.css</a> <a href=\""https://publisher.gallerycdn.vsassets.io/css/screen.css\"" rel=\""nofollow noreferrer\"">https://publisher.gallerycdn.vsassets.io/css/screen.css</a></p>  <p>(<em>I've changed my publisher account name to the generic \""publisher\"" string for ease</em>)</p>  <p>I've opened the .vsix in 7zip  and the folder and css files are in the package.  After many hours of Googling and hunting through stackoverflow  I'm unable to find a solution. </p>  <p>I tried changing the entry in \""files\"" to be simply:</p>  <pre><code>{    \""path\"": \""css\""     \""addressable\"": true } </code></pre>  <p>However this had no effect.</p>  <p>Is anyone able to advise me on what I'm missing or doing wrong?</p>""",azure-devops
56897724,Can I change the App Service Plan/App Service to use the App Services Environment <p>I first created the App Service Plan and App service and later created the App Services Environment. Now I want to change the App Service Plan to use the newly configured ASE  but not able to change it. I created another App Service Plan to use the ASE  but then it was not visible under the Change App Service Plean within App Services.</p>  <p>I created another App Service Plan to use the ASE  but then it was not visible under the Change App Service Plean within App Services.</p>,azure-web-app-service
51546537,"Azure Function Proxy to root <p>Anyone know what I am missing here?</p>  <p>I want my proxy to route all requests to my azure function root URL  to my function.</p>  <p>So that this link  <a href=\https://myfunction.azurewebsites.net/\"" rel=\""nofollow noreferrer\"">https://myfunction.azurewebsites.net/</a> works the same as this link <a href=\""https://myfunction.azurewebsites.net/MYShinyNewFunction\"" rel=\""nofollow noreferrer\"">https://myfunction.azurewebsites.net/MYShinyNewFunction</a></p>  <p>Here is my proxy.json</p>  <pre><code>    {   \""$schema\"": \""http://json.schemastore.org/proxies\""    \""proxies\"": {     \""Root URI to Redirector Trigger Function\"": {       \""matchCondition\"": {         \""route\"": \""/{*path}\""          \""methods\"": [           \""GET\""         ]       }        \""backendUri\"": \""https://localhost/{*path}\""     }   } } </code></pre>""",azure-functions
52153080,"How to protect against deletion of a blob container? <p>It's easy to both create and delete blob data. There are ways to protect from accidental data loss  ex:</p>  <ul> <li>Resource locks to protect against accidental storage account deletion</li> <li>Azure RBAC to limit access to account/keys.</li> <li><a href=\https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-soft-delete\"" rel=\""nofollow noreferrer\"">Soft delete</a> to recover from accidental blob deletion.</li> </ul>  <p>This is already a good package  but it feels like there's a weak link. AFAIK   blob container lacks such safety as for account/blobs. </p>  <p>Considering that containers are a good unit to work with for blob enumeration and batch-deleting  that's bad.</p>  <p><strong>How to protect against accidental/malicious container deletion and mitigate the risk of data loss?</strong></p>  <h3>What I've considered..</h3>  <p><strong>Idea 1:</strong> Sync copy of all data to another storage account - but this brings the synchronization complexity (incremental copy?) and notable cost increase.</p>  <p><strong>Idea 2:</strong> Lock up the keys and force everyone to work on carefully scoped SAS keys  but that's a lot of hassle with dozens of SAS tokens and their renewals  + sometimes container deletion actually is required and authorized. Feels complex enough to break. I'd prefer a safety anyway.</p>  <p><strong>Idea 3:</strong> Undo deletion somehow? According to <a href=\""https://docs.microsoft.com/en-us/rest/api/storageservices/delete-container\"" rel=\""nofollow noreferrer\"">Delete Container documentation</a>  the container data is not gone immediately:</p>  <blockquote>   <p>The Delete Container operation marks the specified container for deletion. The container and any blobs contained within it are later deleted during garbage collection.</p> </blockquote>  <p>Though  there is no information on when/how the storage account garbage collection works or if/how/for how long could the container data be recovered. </p>  <p>Any better options I've missed?</p>""",azure-storage
52817138,"Azure app service continuous integration MSI Error 400 <p>When I deploy .net core app to Azure app service and enable continuous integration  I get error \Please configure Managed Service Identity (MSI) for virtual machine '<a href=\""https://aka.ms/azure-msi-docs\"" rel=\""nofollow noreferrer\"">https://aka.ms/azure-msi-docs</a>'. Status code: 400  status message: Bad Request\""<img src=\""https://i.stack.imgur.com/1LBZa.png\"" alt=\""enter image description here\""></p>""",azure-web-app-service
50323559,"Azure Functions Script Compilation Failed <p>I'm trying to create an Azure Function with Docker. When I create a Function with <code>func new</code>  it works fine and when I go to <a href=\http://localhost:8182/api/HttpTriggerCSharp?name=John\"" rel=\""nofollow noreferrer\"">http://localhost:8182/api/HttpTriggerCSharp?name=John</a> I get the message </p>  <blockquote>   <p>Hello  John</p> </blockquote>  <p>Now I'm trying to run the same project but I changed the code. The previous code was this:</p>  <pre><code>#r \""Newtonsoft.Json\""  using System.Net; using Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.Primitives; using Newtonsoft.Json;  public static IActionResult Run(HttpRequest req  TraceWriter log) { log.Info(\""C# HTTP trigger function processed a request.\"");  string name = req.Query[\""name\""];  string requestBody = new StreamReader(req.Body).ReadToEnd(); dynamic data = JsonConvert.DeserializeObject(requestBody); name = name ?? data?.name;  return name != null     ? (ActionResult)new OkObjectResult($\""Hello  {name}\"")     : new BadRequestObjectResult(\""Please pass a name on the query string or in the request body\""); } </code></pre>  <p>Now this is my new code:</p>  <p><div class=\""snippet\"" data-lang=\""js\"" data-hide=\""false\"" data-console=\""true\"" data-babel=\""false\"">  <div class=\""snippet-code\"">  <pre class=\""snippet-code-css lang-css prettyprint-override\""><code>#r \""Newtonsoft.Json\""    using System.Net;  using Microsoft.AspNetCore.Mvc;  using Microsoft.Extensions.Primitives;  using Newtonsoft.Json;    public static IActionResult Run(HttpRequest req  TraceWriter log)  {   log.Info(\""C# HTTP trigger function processed a request.\"");     // Parsing query parameters   string name = req.GetQueryNameValuePairs()   .FirstOrDefault(q =&gt; string.Compare(q.Key  \""name\""  true) == 0)   .Value;   log.Info(\""name = \"" + name);     string numberOfTerms = req.GetQueryNameValuePairs()   .FirstOrDefault(q =&gt; string.Compare(q.Key  \""numberOfTerms\""  true) == 0)   .Value;   log.Info(\""name = \"" + numberOfTerms);     // Validating the parameters received   if (string.IsNullOrWhiteSpace(name) || string.IsNullOrWhiteSpace(numberOfTerms))   {    var errorResponse = req.CreateResponse(HttpStatusCode.BadRequest                                           \""Please pass a name and the number of digits on the query string.\"");     return errorResponse;   }     int termsToShow;   try   {     termsToShow = Int32.Parse(numberOfTerms);   }    catch (FormatException e)   {    var errorResponse = req.CreateResponse(HttpStatusCode.BadRequest                                           \""The numberOfTerms parameter must be an integer!\"");     return errorResponse;   }     if (termsToShow &lt; 0 || termsToShow &gt; 100) {     var errorResponse = req.CreateResponse(HttpStatusCode.BadRequest                                           \""Please pass a numberOfTerms parameter between 0 and 100.\"");     return errorResponse;   }     // Building the response   string incompleteResponse = \""Hello  \"" + name + \""  you requested the first \"" + numberOfTerms + \"" terms of the Fibonacci series. Here they are: \"";   string completeResponse = GenerateFibonacciTerms(incompleteResponse  termsToShow);   var response = req.CreateResponse(HttpStatusCode.OK  completeResponse);      // Returning the HTTP response with the string we created   log.Info(\""response = \"" + response);   return response;  }    public static string GenerateFibonacciTerms(string incompleteResponse  int termsToShow)  {          int a = 0;      int b = 1;      string temporalString = \""\"";            for (int i = 0; i &lt; termsToShow; i++)      {          int temp = a;          a = b;          b = temp + b;          temporalString = temporalString + temp.ToString() + \"" \"";      }     string result = incompleteResponse + temporalString + \""- That's it  have an awesome day!\"";   return result;      }</code></pre>  </div>  </div>  </p>  <p>I build the container then I run it and I get this message: <a href=\""https://i.stack.imgur.com/M8iYz.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/M8iYz.png\"" alt=\""enter image description here\""></a></p>  <p>I've already checked my code with VS Code (I did it in Sublime Text so I didn't have code checking) and all the problems it finds are the same error: <a href=\""https://i.stack.imgur.com/debTn.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/debTn.png\"" alt=\""enter image description here\""></a></p>  <p>And my code has \""errors\"" everywhere: <a href=\""https://i.stack.imgur.com/U2Sgm.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/U2Sgm.png\"" alt=\""enter image description here\""></a></p>  <p>How can I solve this?</p>""",azure-functions
52754096,Azure DevOps project build returning with log4net error <p>I'm trying to build a visual studio 2015 dot-net application which has <code>log4net</code> reference in the code. </p>  <p>When I build in Azure DevOps using Nuget restore  Nuget Tool installer  Visual studio build  Publish Build artifacts I am getting an error:</p>  <blockquote>   <p>Error CS0246: The type or namespace name 'log4net' could not be found (are you missing a using directive or an assembly reference?) Process 'msbuild.exe' exited with code '1'.</p> </blockquote>  <p>Please someone suggest whether I have to add another agent or make some reference to the package/nuget in Azure DevOps. need details since I'm new to Azure DevOps.</p>,azure-devops
47633274,"Microsoft.Solutions/applicationDefinitions internal server error <p>I'm trying to create a Service catalog managed application definition and get the following error :<code>{   \error\"": {     \""code\"": \""InternalServerError\""      \""message\"": \""Encountered an internal server error. The tracking id is '5d5bf382-f101-48d7-bd89-72c72536a4a9'.\""   } }</code></p>  <p>Is there anyway to find out what causes this? I did come across before. And believe it might be something to do with the template. I've tested the following using visual studio and the deployments works correctly. Just uploading the app.zip with the templates causes this error.</p>""",azure-virtual-machine
56626709,Node modules packages are deleted in Azure function after restart the service <p>I want to install puppeteer in Azure linux function. I couldn't install in home directory. I can able to install root directory. But after restart the service the installed packages are deleted. can anyone suggest the solution to install puppeteer in Azure function</p>,azure-functions
12801076,CloudQueue GetMessage vs GetMessages <p>I wonder what is  the overhead of getting the messages one by one using the GetMessage vs GetMessages?  Should I always use GetMessages(32) and will it have any advantage over GetMessage()?</p>,azure-storage
53056587,Call external API on change to Azure SQL database table <p>We have a table called Guest in an Azure SQL database. We also have a campaign management tool sitting behind an API on the providers cloud.</p>  <p>When a record is created  updated or deleted in the Guest table  we would like to call the API in order to update the campaign management tool with the latest information about the Guest.</p>  <p>Our initial idea was to hook up a database trigger to a C# .NET Azure Function  however  it looks like this is only supported in Cosmos DB.</p>  <p>We would prefer not to have an application running on a scheduled task that periodically checks for changes in the database and sends these changes to the API.</p>  <p>We have also been reading about creating CLR stored procedures but it looks like these are not supported in Azure SQL databases.</p>  <p>Looking forward to hearing ideas &amp; suggestions.</p>,azure-functions
38220335,"Azure  R: showing the Standard Error <p>When I develop an experiment on Azure ML I have the chance to insert the \Execute R Script\"" module. When I have runned it  I can explore the outputs produced by the module itself.</p>  <p><a href=\""https://i.stack.imgur.com/RzLGZ.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/RzLGZ.png\"" alt=\""The output window\""></a></p>  <p>My problem is that I have two modules: I do a filtering on a dataset in the first and use the resulting dataset in the second. Then I create a web service with it. Problem: when the filtering gives a null dataset this possibly create problems in the functions on the second module.</p>  <p>I want to find a way to \""write\"" in the \""Standard Error\"" space. I have tried to use:</p>  <pre><code>if (length(dataset$column1)==0) {warning(\""Empty filtering!!!!\"")} </code></pre>  <p>but it does not work. </p>""",azure-web-app-service
52401386,Azure App Service Plan - Is there any impact on availability with multiple instances? <p>If app service plan has multiple instances and one of the instance crashes for some reason. the other instances will continue to run without impacting app? </p>,azure-web-app-service
39676841,"Stop multiple Azure VMs at the same time using Azure PowerShell <pre><code>Get-AzureRmVM -ResourceGroupName RG-VNETS |      ForEach-Object {          Get-AzureRmVM -ResourceGroupName RG-VNETS -Name $_.Name -Status      } |      ForEach-Object {          if (-Not ($_.Statuses[1].DisplayStatus -like \*deallocated*\"")) {              Stop-AzureRmVM -ResourceGroupName RG-VNETS -Name $_.Name -Force          }      } </code></pre>  <p>I've got this script that stops all my Azure VMs  the catch here is that this script shuts down one VM at a time. </p>  <p>i.e. if I have three VMs: VM1  VM2  VM3</p>  <p>The script doesn't shut down VM2 until VM1 is fully shutdown and so on. I don't know if there's a way to tell PowerShell not to wait for each VM to be fully shutdown to proceed with the following one.</p>""",azure-virtual-machine
49333744,"Symfony 4 on Azure Windows - Very slow output (3-10 secounds) <p>I'm developing on Azure PHP applications with Symfony 4. Currently is a standard installation without a database or extensions: <a href=\http://symfony.com/doc/current/setup.html\"" rel=\""nofollow noreferrer\"">http://symfony.com/doc/current/setup.html</a></p>  <p>I start the server with \""php bin / console server: run\"" Then I call \""<a href=\""https://localhost:8000\"" rel=\""nofollow noreferrer\"">https://localhost:8000</a>\"" in the browser.</p>  <p>The page \""Hello Word\"" appears after ~ 5-10 seconds  although the page is rendered within ~ 300ms (internal Degug Tool of Symfony  when Symfony dont have to rebuild the cache ...).</p>  <p>Something slows down the every output  after the page is rendered with PHP ...The same program runs on my laptop at lightning speed  after 300ms the page is visible ...)</p>  <p>I would be very happy about any help. I use Azure Virtual Machine (Windows Server 2012)</p>  <p>Many thanks &amp; Best regards Simon</p>""",azure-virtual-machine
55553524,"Which Azure Storage method is best for a temporary file transfer? <p>I want to automate the transfer of files from a website not hosted in Azure to my clientâ€™s premises.</p>  <p>I am considering having an API on the website send the files to Azure Blob Storage   and then having another API running at the client site  download them.</p>  <p>Both would make use of the Azure storage API  which I like because it is easy to implement.</p>  <p>The files do not need to stay in Azure and can be deleted from storage once they are downloaded.</p>  <p>However I am wondering if there is a faster way.</p>  <p>Should I be using Hot Blob Storage or File Storage perhaps?</p>  <p>I looked at <a href=\https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers</a> but am still unclear as to the fastest method for my use case.</p>""",azure-storage
49236193,How to lock an Azure web app down to a specific group of users <p>This should really be a basic question  but I can't find the answer anywhere.</p>  <p>I've got a website that I'm hosting as an Azure Web App. I've created an App Registration and I've associated the Web App with the App. Now  I'm prompted to log on before being allowed to view the web site. So far so good  but I want to lock it down so that only a specific group of users has access to the site.</p>  <p>I go to Enterprise Applications and I give permission the application to certain users/groups. But I can still log into the website as any user in the tenancy.</p>  <p>How do I ensure that only a certain group of users can log into the website?</p>,azure-web-app-service
53127436,"Azure Based OData Query Failure with Socket Errors <p>I have three apps querying the same data service on Azure. One has no issues  but two of them are receiving \errors. They are using a Linq query  i.e. \""System.Linq.IQueryable queryResult = entities.Accts.Where(a => a.AN == \""XXX\"");\""</p>  <p>The errors are:      1. WebException: The underlying connection was closed: An unexpected error occurred on a send.     2. IOException: Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host.     3. SocketException: An existing connection was forcibly closed by the remote host</p>  <p>Interesting  having captured the actual sent \""request\"" communication messages from the failing apps and using them in a browser  I get good responses  not errors.</p>  <p>I actually took copies of the OData connection files from the working app and used them to replace their equivalents in a copy of a failing app with no success; same errors.</p>  <p>Ideas?</p>""",azure-devops
43440681,Azure 'Web App on Linux' app service Application logging <p>I am currently using Azure 'Web app on Linux' that leverages docker containers to host a java app and a python app via private registry(Azure Container Registry) and I have yet to find a way to collect and analyze the application logs inside the container.</p>  <p>The goal is to analyze the application logs either by OMS  application insight or storage analytics. I understand that 'Web app on linux' is still in a preview state but there is no official documentation on what features are currently supported.</p>  <p>Does Azure 'Web app on Linux' via containers support exporting logs to blob storage or an application insight SDK for JAVA and Python yet? Plenty of documentation on how to configure it for asp.net and standard web app service but not much I can find out 'Web app on Linux containers'.</p>  <p><strong>What I have attempted so far with my JAVA application:</strong> - Install JAVA SDK and log4js appender. I do see access/request logs in application insight but not my application logs inside the container.</p>  <p>What is the best solution or strategy to collect/view/analyze container application logs in 'Web App on Linux'?</p>  <p>Thanks and regards!</p>,azure-web-app-service
54009016,Gulp-compiled CSS folder missing from the Azure DevOps pipeline Build Artifact <h2>A little background...</h2>  <p>I have a small dotnet core application that is hosted on Azure and is being built and deployed using Azure DevOps Pipelines. Before we started using the DevOps Pipelines the CI was hooked up directly to Azure which compiled fine but took an actual lifetime to deploy  hence the decision to move.</p>  <p><strong>However  the build pipeline no longer compiles or outputs the sass/css folder</strong></p>  <p>Everything else works okay - I check in  the Build pipeline picks up my commits and has the following steps:</p>  <ol> <li>Restore [.NET Core]</li> <li>Build [.NET Core]</li> <li>Publish [.NET Core]</li> <li>Publish Build Artifact</li> </ol>  <p>Part of step 3 (Publish) uses a Gulp task:</p>  <pre><code>gulp.task('prod'  function (callback) {     runSequence('clean' 'set-prod'      ['icon-sprite'  'logo-sprite'  'images'  'sass'  'modernizr'  'mainjs'  'adminjs']              callback); }); </code></pre>  <p>And locally (and previously) this generated five folders:</p>  <blockquote>   <ul>   <li>icons  </li>   <li>img  </li>   <li>js  </li>   <li>logos  </li>   <li>css (now mysteriously missing in action)  </li>   </ul> </blockquote>  <h2>Variations I've tried</h2>  <p>I've tried deleting my local css folder and running the CLI <code>dotnet publish</code> <em>exactly the same way</em> the Pipeline does and that appears to work fine locally.</p>  <p>I've also stripped the sass task way back in case that was causing an issue somewhere in the pipeline  so that now looks like this:</p>  <pre><code>return gulp.src('src/sass/style.scss')     .pipe(sass({outputStyle: 'compressed'}))     .pipe(gulp.dest('wwwroot/dist/css)); </code></pre>  <p>I can see all of the output in the console logs on the Pipeline and it successfully executes the sass task:</p>  <pre><code>2019-01-02T14:43:51.3558593Z   [14:43:51] Starting 'sass'... 2019-01-02T14:43:51.9284145Z   [14:43:51] Finished 'sass' after 524 ms </code></pre>  <p>There are no other errors or warnings in the build script and everything completes and fires off the Release pipeline (which copies the artifact up to the Azure site).</p>  <h2>Speculation</h2>  <p>I would expect an error somewhere... but nothing - all of the green ticks are downright cheerful... so I'm a little stumped at what may or may not be happening! I can only think that there must be some dependency or something missing in the Pipeline environment? Orrrrr maybe I'm missing a Pipeline step?</p>  <p>Any help or nudges or ideas would be greatly appreciated! Thank you for sticking it out through my small essay and for any help you can provide :)</p>,azure-devops
43805366,"Disable RapidFail Protection in WebApp <p>I have recently migrated from Azure Cloud Service to Azure Web App. Earlier I use to Disable the rapidFailProtection from my Webrole class. After the migration to Web App  I have remove the webrole class and added the code of rapidFail in the Application startup routine of the global.asax file. But it gave an error: <strong>role discovery data is unavailable</strong></p>  <p>at the following line:</p>  <pre><code>       Dim mainSite =  serverManager.Sites(RoleEnvironment.CurrentRoleInstance.Id + \_Web\"") </code></pre>  <p>How can I achieve the same functionality for my Azure Web App?</p>""",azure-web-app-service
55021904,"Azure Blob Storage Shared Access Signature (SAS) - Signature did not match <p>I'm trying to deploy a VM by uploading an ARM Template and Parameters file into a private Blob storage container and then download them when needed. The files upload into the container fine  but when the trying to download them the SAS token fails to authenticate giving the error:</p>  <pre><code>Microsoft.Rest.Azure.CloudException:  Unable to download deployment content from 'https://cloudstationsbackendsa.blob.core.windows.net/workstation-templates/CreateVMTemplate.json?sv=2018-03-28&amp;sr=b&amp;sig=GHgWUiEG7bG3%2FDN4cjSsmHGrBTdM8F2LRxNTss5cJB0%3D&amp;st=2019-03-06T11:16:42Z&amp;se=2019-03-06T11:31:42Z&amp;sp=r' </code></pre>  <p>Visiting this URL in a browser produces the following error:</p>  <pre><code>&lt;Error&gt; &lt;Code&gt;AuthenticationFailed&lt;/Code&gt; &lt;Message&gt; Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. RequestId:8e274bc1-101e-0011-3f0c-d45f43000000 Time:2019-03-06T11:03:53.3144543Z &lt;/Message&gt; &lt;AuthenticationErrorDetail&gt; Signature did not match. String to sign used was r 2019-03-06T10:58:39Z 2019-03-06T11:13:39Z /blob/cloudstationsbackendsa/workstation-templates/CreateVMTemplate.json 2018-03-28 &lt;/AuthenticationErrorDetail&gt; &lt;/Error&gt; </code></pre>  <p>This is the method used to upload the files and generate the SAS tokens:</p>  <pre><code>public async Task&lt;StorageAccountAccessDTO&gt; UploadTemplatesAsync(string azureIdentifier) {     // Access to Storage Account                var account = CloudStorageAccount.Parse(_config.GetValue&lt;string&gt;(\ConnectionStrings:StorageAccount\""));     var serviceClient = account.CreateCloudBlobClient();     var container = serviceClient.GetContainerReference(\""workstation-templates\"");      // Upload VM ARM Template     var templateBlob = container.GetBlockBlobReference(\""CreateVMTemplate.json\"");     await templateBlob.UploadFromFileAsync(\""CreateVMTemplate.json\"");      // Upload VM ARM Parameters     var parameterBlob = container.GetBlockBlobReference(\""Parameters.json\"");     await parameterBlob.UploadFromFileAsync(\""Parameters.json\"");      // Create SAS Tokens     SharedAccessBlobPolicy sasConstraints = new SharedAccessBlobPolicy();     sasConstraints.SharedAccessStartTime = DateTimeOffset.UtcNow.AddMinutes(-5);     sasConstraints.SharedAccessExpiryTime = DateTimeOffset.UtcNow.AddMinutes(10);     sasConstraints.Permissions = SharedAccessBlobPermissions.Read;      var accessDTO = new StorageAccountAccessDTO()     {         TemplateURL = templateBlob.Uri + templateBlob.GetSharedAccessSignature(sasConstraints)          ParametersURL = templateBlob.Uri + parameterBlob.GetSharedAccessSignature(sasConstraints)     };      return accessDTO; } </code></pre>  <p>The SAS tokens are appended to the URI of the blob and returned in a StorageAccountAccessDTO  this is passed into the method below to produce the VM:</p>  <pre><code>public async Task CreateVirtualMachineAsync(string azureIdentifier  StorageAccountAccessDTO accessDTO) {     await _azure.Deployments.Define(\""myDeployment\"")         .WithExistingResourceGroup(azureIdentifier + \""-RG\"")         .WithTemplateLink(accessDTO.TemplateURL  \""1.0.0.0\"")         .WithParametersLink(accessDTO.ParametersURL  \""1.0.0.0\"")         .WithMode(DeploymentMode.Incremental)         .CreateAsync(); } </code></pre>  <p>Thanks for your time and let me know if you require any extra details!</p>""",azure-storage
43185645,"How to change default port of bitnami mongodb vm in microsoft azure <p>I am deploying my NodeJS web application project in Microsoft azure. I am using Bitnami MongoDB vm for my server  the default port 27017 is not secured. Due to security reason I wanted to change some 27171  I have changed in mongo.conf file but its giving below error.</p>  <p>mongod.conf file-</p>  <p><div class=\snippet\"" data-lang=\""js\"" data-hide=\""false\"" data-console=\""true\"" data-babel=\""false\"">  <div class=\""snippet-code\"">  <pre class=\""snippet-code-js lang-js prettyprint-override\""><code>dbpath=/data/db    #where to log  logpath=/opt/bitnami/mongodb/log/mongodb.log    logappend=true    #bind_ip = 127.0.0.1  port = 27171    journal=true    # Turn on/off security.  Off is currently the default  #noauth = true  auth = true</code></pre>  </div>  </div>  </p>  <p>The error is</p>  <p><div class=\""snippet\"" data-lang=\""js\"" data-hide=\""false\"" data-console=\""true\"" data-babel=\""false\"">  <div class=\""snippet-code\"">  <pre class=\""snippet-code-js lang-js prettyprint-override\""><code>MongoDB shell version v3.4.0  connecting to: mongodb:///opt/bitnami/mongodb/tmp/mongodb-27017.sock/  2017-04-03T13:07:48.437+0000 W NETWORK  [main] Failed to connect to /opt/bitnami/mongodb/tmp/mongodb-27017.sock:0  reason: No such file or directory  2017-04-03T13:07:48.462+0000 E QUERY    [main] Error: couldn't connect to server/opt/bitnami/mongodb/tmp/mongodb-27017.sock:27017  connection attempt failed :  connect@src/mongo/shell/mongo.js:234:13  @(connect):1:6  exception: connect failed</code></pre>  </div>  </div>  </p>""",azure-virtual-machine
51253862,Azure app service custom domain is not working with www prefix <p>I have a custom domain within my app service  but can't access my web app with www prefix only without. I get error ERR_NAME_NOT_RESOLVED when trying to access with www prefix. I define my custom domain as subdomain.domain.com </p>,azure-web-app-service
36240179,Azure Resource Manager VM can't connect from Internet <p>I created a azure vm through resource manager and deployed an application on it. the application works fine when you try to access it from the vm. but when i try it from outside(through internet) it doesn't work. i created an inbound security rule in NSG and opened the port through vm firewall inbound rules too. please give some tips as to why this isn't working </p>,azure-virtual-machine
56039457,"pipeline calling same powershell function twice  will not recognize first call to function <p>I have the pipeline below:</p>  <pre><code>trigger: - master  jobs: - job: BuildDacPac   steps:   - task: MSBuild@1     displayName: 'Build DACPAC'     inputs:       solution: 'AzureDevops-Fa-Snapshot-CI-Pipeline-Adv.sln'       msbuildArguments: '/property:OutDir=bin\\Release'  - job: RefreshIntegrationTestDb   dependsOn: BuildDacPac   workspace:     clean: all   steps:   - powershell: |       $securePassword = ConvertTo-SecureString -String '$(pfaPassword)' -AsPlainText -Force       $pfaCreds = New-Object System.Management.Automation.PSCredential '$(pfaUsername)'  $securePassword       Invoke-PfaDbRefresh -RefreshDatabase $(refreshDatabase) `                           -RefreshSource   $(refreshSource) `                           -DestSqlInstance Z-STN-WIN2016-A\\DEVOPSIAT `                           -PfaEndpoint     $(pfaEndpoint) `                           -PfaCredentials  $pfaCreds  - job: DeployDacPac   dependsOn: RefreshIntegrationTestDb   steps:   - script: sqlpackage.exe /Action:Publish /SourceFile:\$(System.DefaultWorkingDirectory)\\AzureDevOps-Fa-Snapshot-Ci-Pipeline-Adv\\bin\\Release\\AzureDevOps-Fa-Snapshot-Ci-Pipeline-Adv.dacpac\"" /TargetConnectionString:\""server=$(iatInstanceName);database=$(refreshDatabase)\""   - job: ParallelDevDatabaseRefresh   dependsOn: RefreshIntegrationTestDb   pool: $(agentPool)   strategy:      matrix:       dev_1:         instanceName: Z-STN-WIN2016-A\\DEVOPSDEV1       dev_2:         instanceName: Z-STN-WIN2016-A\\DEVOPSDEV2       dev_3:         instanceName: Z-STN-WIN2016-A\\DEVOPSDEV3       dev_4:         instanceName: Z-STN-WIN2016-A\\DEVOPSDEV4   steps:   - powershell: |       $securePassword = ConvertTo-SecureString -String '$(pfaPassword)' -AsPlainText -Force       $pfaCreds = New-Object System.Management.Automation.PSCredential '$(pfaUsername)'  $securePassword       Invoke-PfaDbRefresh -RefreshDatabase $(refreshDatabase) `                           -RefreshSource   $(refreshSource) `                           -DestSqlInstance $(instanceName) `                           -PfaEndpoint     $(pfaEndpoint) `                           -PfaCredentials  $pfaCreds </code></pre>  <p>The call to Invoke-PfaDbRefresh in the job ParallelDevDatabaseRefresh works without any problems whatsoever  however the call to this function in the RefreshIntegrationTestDb job fails with:</p>  <pre><code>##[section]Starting: PowerShell ============================================================================== Task         : PowerShell Description  : Run a PowerShell script on Windows  macOS  or Linux. Version      : 2.148.0 Author       : Microsoft Corporation Help         : [More Information](https://go.microsoft.com/fwlink/?LinkID=613736) ============================================================================== Generating script. ========================== Starting Command Output =========================== [command]/usr/bin/pwsh -NoLogo -NoProfile -NonInteractive -Command . '/home/vsts/work/_temp/022ae053-d678-4d53-9f14-48a828a2d619.ps1' refreshDatabase : The term 'refreshDatabase' is not recognized as the name of a cmdlet  function  script file  or operable program. Check the spelling of the name  or if a path was included  verify that the path is correct and try again. At /home/vsts/work/_temp/022ae053-d678-4d53-9f14-48a828a2d619.ps1:4 char:40 + Invoke-PfaDbRefresh -RefreshDatabase $(refreshDatabase) ` +                                        ~~~~~~~~~~~~~~~ + CategoryInfo          : ObjectNotFound: (refreshDatabase:String) []  ParentContainsErrorRecordException + FullyQualifiedErrorId : CommandNotFoundException  ##[error]PowerShell exited with code '1'. ##[section]Finishing: PowerShell </code></pre>  <p>I'm struggling to understand why the pipeline can recognise the powershell function call in one part of the pipeline but not another.</p>""",azure-devops
56532051,"Azure Manage IIS Web 'x' is not recognized as an internal or external command operable program or batch file.\ <p>I am Deploying My website and in the task WinRM I am getting the error \""##[error]Microsoft.PowerShell.Commands.WriteErrorException: Deployment on one or more machines failed. System.Exception: 'x' is not recognized as an internal or external command operable program or batch file.\""</p>  <p>What is \""X\""?</p>  <pre><code>2019-06-10T18:29:43.2417805Z ##[section]Starting: Manage IIS App:xxWeb 2019-06-10T18:29:43.2417805Z ============================================================================== 2019-06-10T18:29:43.2417805Z Task         : WinRM - IIS Web App Management 2019-06-10T18:29:43.2417805Z Description  : Connect via WinRM  to create or update the Website and App Pool locally on IIS 2019-06-10T18:29:43.2417805Z Version      : 1.3.4 2019-06-10T18:29:43.2417805Z Author       : Microsoft Corporation 2019-06-10T18:29:43.2417805Z Help         : [More Information](http://aka.ms/IISMgmt) 2019-06-10T18:29:43.2417805Z ============================================================================== 2019-06-10T18:29:43.2574066Z Preparing task execution handler. 2019-06-10T18:29:43.7574097Z Executing the powershell script: D:\\TFSVSOWork\\_tasks\\IISWebAppMgmt_0f5cd14f-3c01-4d5c-8f7a-eb96c5738dcc\\1.3.4\\Main.ps1 2019-06-10T18:29:44.0230429Z Started creating website: zzWeb 2019-06-10T18:29:44.0230429Z  2019-06-10T18:29:44.0230429Z  2019-06-10T18:29:44.1167998Z Performing deployment in parallel on all the machines. 2019-06-10T18:29:44.1167998Z  2019-06-10T18:29:44.1167998Z  2019-06-10T18:29:44.1324152Z Deployment started for machine: ABC with port 5985. 2019-06-10T18:29:44.1324152Z  2019-06-10T18:29:44.1324152Z  2019-06-10T18:29:55.3845707Z Deployment status for machine ABC : Failed 2019-06-10T18:29:55.3845707Z  2019-06-10T18:29:55.3845707Z  2019-06-10T18:29:55.3845707Z Deployment failed on machine ABC with following message : System.Exception: 'x' is not recognized as an internal or external command operable program or batch file. 2019-06-10T18:29:55.3845707Z SITE object \""zzWeb\"" changed 2019-06-10T18:29:55.3845707Z  2019-06-10T18:29:55.3845707Z  2019-06-10T18:29:55.4001931Z  2019-06-10T18:29:55.4158230Z  2019-06-10T18:29:55.4158230Z ##[error]Microsoft.PowerShell.Commands.WriteErrorException: Deployment on one or more machines failed. System.Exception: 'x' is not recognized as an internal or external command operable program or batch file. 2019-06-10T18:29:55.4158230Z SITE object \""zzWeb\"" changed 2019-06-10T18:29:55.4158230Z For more info please refer to http://aka.ms/iisextnreadme 2019-06-10T18:29:55.4470744Z ##[error]PowerShell script completed with 1 errors. 2019-06-10T18:29:55.4470744Z ##[section]Finishing: Manage IIS App:zzWeb </code></pre>  <p>I went poking around with the Event Viewer  but not seeing anything in logs close to this time.  I have this working on DEV and Test servers  I'm sure some one for got to set something up on these new servers  But I cant tell what it is.</p>""",azure-devops
51442184,"SendGrid Attachment Error : cannot convert from 'System.IO.MemoryStream' to 'string' <p>I have file in azure storage as PDF. Now I want to attach it as attachment in mail. For mail sending I am using SendGrid version 9.8.0.0. But it is giving error like 'cannot convert from 'System.IO.MemoryStream' to 'string''.</p>  <p>Code is like below :</p>  <pre><code>CloudBlockBlob blob = container.GetBlockBlobReference(fileName);              var stream = new MemoryStream();             blob.DownloadToStream(stream);             stream.Seek(0  SeekOrigin.Begin);             ContentType content = new ContentType(MediaTypeNames.Text.Plain);             stream.Position = 0;              #endregion              var msg = new SendGridMessage()             {                 From = new EmailAddress(email.FromMail)                  Subject = email.Subject                  HtmlContent = email.MailBody               };              msg.AddAttachment(stream  \originalfilename.png\""); &lt;-- here giving error             msg.AddTo(new EmailAddress(email.Recipient)); </code></pre>  <p>What is wrong in this??</p>""",azure-storage
39934737,"Azure Account Shared Access Signiture <p>I am trying to construct an Account level Shared Access Signiture so my client can access all containers in a storage account. I am following these docs <a href=\https://msdn.microsoft.com/en-US/library/azure/mt584140.aspx\"" rel=\""nofollow\"">Account SAS</a>. It seems straight forward enough but I keep getting the following error message: </p>  <p>\""Signature did not match. String to sign used was accountname\\nrl\\nb\\nsc\\n\\n2016-10-09\\n\\n\\n2015-04-05\\n\"".</p>  <p>My parameters are identical so I suspect it has something to do with how I am hashing the String to Sign. Below is how I construct the token.</p>  <pre><code>var crypto = require('crypto'); var accountName = 'accountname'; var accountKey = 'tH37FTlG3TUT86caMrt2y5kOzof8nFqqA6spzg6r7HPRojE1zDiLJD/xE4oLFDh4RNqAmymvlV7fm8W4SF8cJg==';  var signedPermissions = \""sp=rl\""; var signedServcies = \""ss=b\""; var signedResourceType = \""srt=sc\""; var signedExpiry = \""se=2016-10-09\""; var signedVersion = \""sv=2015-04-05\"";  var stringToSign = accountName + \""\\n\"" + signedPermissions + \""\\n\"" + signedServcies + \""\\n\"" + signedResourceType + \""\\n\"" + signedExpiry + \""\\n\"" + signedVersion + \""\\n\""; var hmacsha256 = crypto.createHmac('sha256'  accountKey).update(stringToSign).digest('base64'); var token = signedPermissions + \""&amp;\"" + signedServcies + \""&amp;\"" + signedResourceType + \""&amp;\"" + signedExpiry + \""&amp;\"" + signedVersion + \""&amp;sig=\"" + hmacsha256; </code></pre>  <p>I have tried using crypto-js as well but to no avail. The final URL used to access a blob in a container is...</p>  <p>\""<a href=\""https://accountname.blob.core.windows.net/containername/blobName?srt=sc&amp;se=2016-10-09&amp;api-version=2015-04-05&amp;sp=rl&amp;ss=b&amp;sv=2015-04-05&amp;sig=IFD2wyfRAsHGU5IFg3RbwSJW6tRE0m0%2FxgAYvJ%2FmnEk%3D\"" rel=\""nofollow\"">https://accountname.blob.core.windows.net/containername/blobName?srt=sc&amp;se=2016-10-09&amp;api-version=2015-04-05&amp;sp=rl&amp;ss=b&amp;sv=2015-04-05&amp;sig=IFD2wyfRAsHGU5IFg3RbwSJW6tRE0m0%2FxgAYvJ%2FmnEk%3D</a>\""</p>  <p>I have been trying for days and really would appreciate knowing what I'm doing wrong. Thanks.</p>""",azure-storage
42493463,What events does an Azure Windows VM receive during a planned maintenance shutdown? <p>When Azure shuts down a VM for planned maintenance  what messages do running services see  if any?</p>  <p>For example  do they get a ServiceBase.OnShutdown() message and  if so  how long does the service / server get to complete shutdown processing?</p>  <p>Does MS give any extra leeway to its own apps? E.g. if a VM is running SQL Server  will Azure wait for SQL Server to stop cleanly before shutting down the VM?</p>  <p>[I can't find this in the documentation and  unfortunately  I don't have the access or the programming skills to try it out for myself.]</p>,azure-virtual-machine
45800085,"Azure VMSS with Custom Image using Powershell returned error: DiskProcessingError <p>I am having problem deploying vmss using custom images via powershell. The following is my code for the powershell deployment:</p>  <pre><code>#New-AzureRmResourceGroup -Location southeastasia -Name arkgenegroup1 # Resource group name from above $rg = \myvmss\"" $location = \""southeastasia\""  # Create a config object $vmssConfig = New-AzureRmVmssConfig -Location $location -SkuCapacity 2 -SkuName Standard_A0  -UpgradePolicyMode Automatic   # Reference a virtual machine image from the gallery Set-AzureRmVmssStorageProfile -VirtualMachineScaleSet $vmssConfig -OsDiskCreateOption FromImage -ManagedDisk StandardLRS -OsDiskCaching \""None\"" -OsDiskOsType Linux -ImageReferenceId (Get-AzureRmImage -ImageName image200817 -ResourceGroupName $rg).id   # Set up information for authenticating with the virtual machine Set-AzureRmVmssOsProfile $vmssConfig -AdminUsername admin -AdminPassword adminpass -ComputerNamePrefix myvmss  # Create the virtual network resources  ## Basics $subnet = New-AzureRmVirtualNetworkSubnetConfig -Name \""my-subnet\"" -AddressPrefix 10.0.0.0/24 $vnet = New-AzureRmVirtualNetwork -Name \""my-network\"" -ResourceGroupName $rg -Location $location -AddressPrefix 10.0.0.0/16 -Subnet $subnet  ## Load balancer $publicIP = New-AzureRmPublicIpAddress -Name \""PublicIP\"" -ResourceGroupName $rg -Location $location -AllocationMethod Static -DomainNameLabel \""myuniquedomain\"" $frontendIP = New-AzureRmLoadBalancerFrontendIpConfig -Name \""LB-Frontend\"" -PublicIpAddress $publicIP $backendPool = New-AzureRmLoadBalancerBackendAddressPoolConfig -Name \""LB-backend\"" $probe = New-AzureRmLoadBalancerProbeConfig -Name \""HealthProbe\"" -Protocol Tcp -Port 80 -IntervalInSeconds 15 -ProbeCount 2 $inboundNATRule1= New-AzureRmLoadBalancerRuleConfig -Name \""webserver\"" -FrontendIpConfiguration $frontendIP -Protocol Tcp -FrontendPort 80 -BackendPort 80 -IdleTimeoutInMinutes 15 -Probe $probe -BackendAddressPool $backendPool $inboundNATPool1 = New-AzureRmLoadBalancerInboundNatPoolConfig -Name \""RDP\"" -FrontendIpConfigurationId $frontendIP.Id -Protocol TCP -FrontendPortRangeStart 53380 -FrontendPortRangeEnd 53390 -BackendPort 3389  New-AzureRmLoadBalancer -ResourceGroupName $rg -Name \""myLB\"" -Location $location -FrontendIpConfiguration $frontendIP -LoadBalancingRule $inboundNATRule1 -InboundNatPool $inboundNATPool1 -BackendAddressPool $backendPool -Probe $probe  ## IP address config $ipConfig = New-AzureRmVmssIpConfig -Name \""my-ipaddress\"" -LoadBalancerBackendAddressPoolsId $backendPool.Id -SubnetId $vnet.Subnets[0].Id -LoadBalancerInboundNatPoolsId $inboundNATPool1.Id  # Attach the virtual network to the IP object Add-AzureRmVmssNetworkInterfaceConfiguration -VirtualMachineScaleSet $vmssConfig -Name \""network-config\"" -Primary $true -IPConfiguration $ipConfig  # Create the scale set with the config object (this step might take a few minutes) New-AzureRmVmss -ResourceGroupName $rg -Name \""myvmss\"" -VirtualMachineScaleSet $vmssConfig </code></pre>  <p>Error Code</p>  <pre><code>New-AzureRmVmss : Long running operation failed with status 'Failed'. ErrorCode: DiskProcessingError ErrorMessage: One or more errors occurred while preparing VM disks. See disk instance view for details. StartTime: 8/21/2017 4:59:40 PM EndTime: 8/21/2017 5:00:02 PM OperationID: xxxxxxx-fda7-4f37-acbb-xxxxxxxx Status: Failed At line:1 char:1 + New-AzureRmVmss -ResourceGroupName $rg -Name \""myvmss\"" -VirtualMa ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : NotSpecified: (:) [New-AzureRmVmss]  ComputeCloudException     + FullyQualifiedErrorId : Microsoft.Azure.Commands.Compute.Common.ComputeCloudException Microsoft.Azure.Commands.Compute.Automation.NewAzureRmVmss </code></pre>  <p>I can't seems to figure out what exactly causing the problem  the same image was able to be used to create standalone VM. </p>""",azure-virtual-machine
35782166,"How to list all virtual directories and subdirectories using Azure Storage Client Library for .NET (BLOBS) <p><strong>How to list ALL directories AND subdirectories in a blob container?</strong></p>  <p>This is what I have so far:</p>  <pre><code>public List&lt;CloudBlobDirectory&gt; Folders { get; set; }  public List&lt;CloudBlobDirectory&gt; GetAllFoldersAndSubFoldersFromBlobStorageContainer() {     CloudStorageAccount storageAccount = CloudStorageAccount.Parse(ConfigurationManager.ConnectionStrings[\StorageConnectionString\""].ConnectionString);     CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();     CloudBlobContainer container = blobClient.GetContainerReference(\""mycontainer\"");      if (container.Exists())     {         Folders = new List&lt;CloudBlobDirectory&gt;();          foreach (var item in container.ListBlobs())         {             if (item is CloudBlobDirectory)             {                 var folder = (CloudBlobDirectory)item;                 Folders.Add(folder);                 GetSubFolders(folder);             }         }     }      return Folders; }  private void GetSubFolders(CloudBlobDirectory folder) {     foreach (var item in folder.ListBlobs())     {         if (item is CloudBlobDirectory)         {             var subfolder = (CloudBlobDirectory)item;             Folders.Add(subfolder);             GetSubFolders(subfolder);         }     } } </code></pre>  <p>The above code-snippet gives me the list that I want but I am unsure about the recursive method and other .NET/C# syntax and best practice programming patterns. Simply put  I would like the end result to be as elegant and as performant as possible. </p>  <p><strong>How can the above code-snippet be improved?</strong></p>""",azure-storage
56583056,"Backlog hierarchy displays only temporarily then list is flat <p>When selecting the backlog  the hierarchy of feature > backlog item > task shows for just a second  then goes away and im left with just a \flat\"" list of work items.  What can I check?  Another team member does not have this issue when they view the backlog.  View parents is \""on\""</p>  <p>[ update ] Looks like I had an active \""filter\"" turned on and as soon as I removed everything from my filter  the hierarchy showed back up  for both epics  features and pbi's.  </p>""",azure-devops
54692849,"Why is my nuget package push filtered out in VSTS (Azure Devops) <p>I have an azure DevOps pipeline who compile correctly and the log files indicate a successful \pack\"" into \""D:\\a\\1\\a\\Packages\\Rvi.LA.ObjetsMetiers.1.1.0.nupkg\"".</p>  <p>Concerning the nuget push step  I can see the following in the debug log :</p>  <pre><code>2019-02-14T14:19:43.5995520Z ##[debug]pattern: 'D:\\a\\1\\a\\Packages\\RVI.LA.ObjetsMetiers*.nupkg' 2019-02-14T14:19:44.9183973Z ##[debug]expanding braces 2019-02-14T14:19:44.9184020Z ##[debug]pattern: 'D:/a/1/a/Packages/RVI.LA.ObjetsMetiers*.nupkg' 2019-02-14T14:19:44.9209179Z ##[debug]findPath: 'D:\\a\\1\\a\\Packages' 2019-02-14T14:19:44.9209259Z ##[debug]statOnly: 'false' 2019-02-14T14:19:44.9212246Z ##[debug]findPath: 'D:\\a\\1\\a\\Packages' 2019-02-14T14:19:44.9212452Z ##[debug]findOptions.allowBrokenSymbolicLinks: 'undefined' 2019-02-14T14:19:44.9212597Z ##[debug]findOptions.followSpecifiedSymbolicLink: 'undefined' 2019-02-14T14:19:44.9212885Z ##[debug]findOptions.followSymbolicLinks: 'undefined' 2019-02-14T14:19:44.9223644Z ##[debug]  D:\\a\\1\\a\\Packages (directory) 2019-02-14T14:19:44.9225732Z ##[debug]  D:\\a\\1\\a\\Packages\\Rvi.LA.ObjetsMetiers.1.1.0.nupkg (file) 2019-02-14T14:19:44.9225814Z ##[debug]2 results 2019-02-14T14:19:44.9225888Z ##[debug]found 2 paths </code></pre>  <p>So  it finds two results but strangely indicates \""found 2 paths\"" when one of them is a file.  Anyway  it successfully finds the one who needs to be pushed and detect it is a file.</p>  <p>The problem is in the following part of the log :</p>  <pre><code>2019-02-14T14:19:44.9225984Z ##[debug]applying include pattern 2019-02-14T14:19:44.9235322Z ##[debug]0 matches 2019-02-14T14:19:44.9235403Z ##[debug]0 final results 2019-02-14T14:19:44.9247396Z ##[warning]No packages matched the search pattern. 2019-02-14T14:19:44.9247569Z ##[debug]Processed: ##vso[task.issue type=warning;]No packages matched the search pattern. </code></pre>  <p>It seems to exclude it with the include pattern who is \""$(Build.ArtifactStagingDirectory)\\Packages\\$(NomNuspec)*.nupkg\"" and is translated to \""D:\\a\\1\\a\\Packages\\RVI.LA.ObjetsMetiers*.nupkg\"" in the log above.</p>  <p>I don't understand why it is not found.  Is there something who should hit me in the eye even though two persons looked at it many times?</p>""",azure-devops
29507724,SSH is not working for some VMs in MS Azure <p>I created 4 virtual machine under one cloud service in Microsoft Azure. I tried to ssh to the VMs I created. I am able to do shh to first tow VMs  but not to the last two. What would be the problem. Can anybody help?</p>  <p>Thanks in advance</p>,azure-virtual-machine
47349527,"Parameterise settings.json of Function app for publish <p>For a Proof of Concept  I would like to publish an Azure Function from Visual studio to Azure with a different <code>connectionString</code> value. But I can't figure out how. </p>  <p>In the <code>FunctionApp</code> there is a <code>local.settings.json</code> file. I have added a <code>connectionString</code> to my local database. </p>  <p><code>local.settings.json</code> file:</p>  <pre><code>{   \IsEncrypted\"": false    \""Values\"": {     \""AzureWebJobsStorage\"": \""\""      \""AzureWebJobsDashboard\"": \""\""   }    \""ConnectionStrings\"": {     \""DefaultConnection\"": \""Data Source=.\\;Initial Catalog=declapp;Integrated Security=False;User ID=*****;Password=*****;Connect Timeout=30;Encrypt=False;TrustServerCertificate=True;ApplicationIntent=ReadWrite;MultiSubnetFailover=False\""   } } </code></pre>  <p>I can publish this <code>FunctionApp</code> to Azure with the generated publish profile but I have a database in Azure which is used by the deployed <code>FunctionApp</code>. The first time I had to add the <code>connectionString</code> to the FunctionApp in the Azure Portal. But also when the <code>connectionString</code> needs to be altered  I can only do it in the Azure Portal. </p>  <p>I would like to know how I can add/alter the <code>connectionString</code> in the publishing part as below. How can I achieve this? </p>  <pre><code>{   \""IsEncrypted\"": false    \""Values\"": {     \""AzureWebJobsStorage\"": \""\""      \""AzureWebJobsDashboard\"": \""\""   }    \""ConnectionStrings\"": {     \""DefaultConnection\"": \""&lt;Azure sql connectionstring&gt;\""   } } </code></pre>  <p>Just to be clear: I know it`s a bad practice to have (production) values in source control  but it's for a simple Proof of Concept and I don't want to define a CI/CD pipeline just for this. </p>""",azure-functions
46684313,How to avoid TimeoutError error when connecting to FTP from Azure Function <p>I have written a python module using the package <code>ftplib</code> to retrieve data from my data provider that does the following:</p>  <p>1) Upload a text file in a FTP server using the STOR command.</p>  <p>2) Every minute  retrieve full list of files in a FTP server     directory. If this list satisfies certain conditions  go to the     next step. Repeat this step otherwise.</p>  <p>3) Download all files from a FTP server directory using the RETR command.</p>  <p>I have been running the previous process in a VM for several months without any issue. I've recently decided to move the process in a different cloud environment (Azure Functions - App service plan) in order to reduce the maintenance costs but I've started to get serious error message with step 3 exclusively (steps 1 and 2 work always perfectly).</p>  <pre><code>TimeoutError: [WinError 10060] A connection attempt failed because the  connected party did not properly respond after a period of time  or  established connection failed because connected host has failed to  respond </code></pre>  <p>ATTEMPTS:</p>  <ul> <li>The error tends to happen only when it takes more than 15 minutes or so to run step 2. For this reason  the problem should not be related to closed ports/firewall.</li> <li>I've verified with the data provider and they told me that the problem is not on their side  so the problem is related with the azure function.</li> <li>During step 2  I've tried to send a NOOP message to the FTP and to download a small file from the FTP every minute to keep the connection alive. However  I still get the same error message after a while or when jumping to step 3.</li> <li>When I use an active FTP connection  I still get a (different) error message: <code>ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host</code></li> <li>Close and reopen the FTP connection for every iteration of step 2.</li> </ul>  <p>I have a very strong feeling that even if Azure Functions with the App Service Plan are not supposed to have the 10 minutes timeout of the Consumption Plan  something behind the scenes in Azure still doesn't like long running processes (~30 minutes).</p>,azure-functions
42968044,"NewAzureRmVM: Required parameter 'networkProfile' is missing (null) <p>So I have been trying to create a VM from Linux VHD and getting this error. Following this <a href=\https://pebkac.io/2016/10/mikrotik-chr-in-azure-part-two/\"" rel=\""nofollow noreferrer\"">https://pebkac.io/2016/10/mikrotik-chr-in-azure-part-two/</a></p>""",azure-virtual-machine
54194776,Sharing Agent Queue For Prod and Stag Environment in TFS Build/Release Definition <p>I am trying to setup build and release definition in TFS 2015. I have set up multiple agent queues for different environments Staging  Production  Load  UAT. I have different physical agents for each of this environment and each agent has permission to connect to respective environment to deploy code.</p>  <p>My Question is how do i share agents over these environments. Is it possible to have one agent which has permission to all these environment and can deploy code to  IIS website. My websites name is also same in each environmetn. For e.g. abc.com (UAT)  abc.com (PROD).</p>  <p>TFS version is 2015.</p>,azure-devops
37922937,"Azure File Service shared drive with System.IO not working <p>I have several VM's in Azure that use the same data (pictures etc)  that are stored in a storage account with a File Service setup. </p>  <p>I ran the commands mentioned in <a href=\https://azure.microsoft.com/en-in/documentation/articles/storage-dotnet-how-to-use-files/\"" rel=\""nofollow\"">https://azure.microsoft.com/en-in/documentation/articles/storage-dotnet-how-to-use-files/</a> to mount the drive on the VM's and persist the credentials.</p>  <p>From my c# code however I keep getting exceptions that the path cannot be found.</p>  <pre><code>An exception of type 'System.IO.DirectoryNotFoundException' occurred in mscorlib.dll but was not handled in user code  Additional information: Could not find a part of the path 'X:\\Data\\test'. </code></pre>""",azure-storage
41426330,"Cannot create VM with multiple NICs in Azure <p>I am trying to build an OpenStack cloud in Azure (for OpenStack experimentation) that implements <a href=\http://docs.openstack.org/newton/install-guide-ubuntu/environment-networking.html\"" rel=\""nofollow noreferrer\"">this</a> network architecture.</p>  <p>I have built everything with Azure CLI and got it working right down to the VM creation but receive the following error when adding the second NIC.</p>  <pre><code>error:   Deployment provisioning state was not successful error:   Subnet default referenced by resource /subscriptions/&lt;subscriptionid&gt;/resourceGroups/openstack/providers/Microsoft.Network/networkInterfaces/controller-prov-nic/ipConfigurations/ipconfig2 is not in the same Virtual Network as the subnets of other VMs in the availability set. </code></pre>  <p>Networking is not my strength. Why can't I have two NICs that network to their own VNET? Can anyone suggest how best to implement the topology in the OpenStack link above?</p>  <p>You can download the whole project <a href=\""https://drive.google.com/open?id=0B7LD9BBJctt3b0RxSS0wYWZsVkU\"" rel=\""nofollow noreferrer\"">here</a>. The project builds each resource type in succession. This makes it easier to work with each template file.</p>  <p>Note:</p>  <ol> <li>You need to edit one line in template.json in the VM directory to add your own public SSH key. </li> <li>To build the entire stack (using bash and Azure CLI) just run ./build-all.sh in the top directory. (Assuming you have your Azure credentials stored locally. If not remove the -n switch in build-all.sh.)</li> <li>My project has only built up to the Controller node in the OpenStack pattern listed above.</li> </ol>  <p>Thanks</p>  <p>Bryon</p>""",azure-virtual-machine
50322968,"Getting \BlockCountExceedsLimit\"" exception while using log4net.Appender.AzureAppendBlobAppender <p>I'm using <code>log4net.Appender.AzureAppendBlobAppender</code> to log my web app's info &amp; errors. Sometimes I'm getting the \""BlockCountExceedsLimit\"" exception. It is due to the append blob accepts only 50 000 block commits after that it through the exception (Conflict (409)). I have checked the code and found that it waits for the 512 log events and flush each log entry separately to the append blob. So  we can log only 50 000 log entries in a day.</p>  <p>Can anyone please help me on this? Does anyone know any alternate for this?</p>  <p>Thanks  Karthik</p>""",azure-web-app-service
41809209,"Putting precompiled azure function in a shared assembly <p>Basically I'm trying to create an Azure Function as a precompiled function (as decribed on <a href=\https://github.com/devkimchi/Testing-Precompiled-Azure-Functions\"" rel=\""nofollow noreferrer\"">https://github.com/devkimchi/Testing-Precompiled-Azure-Functions</a>) but with the extra Thing that I want the DLL to be in a shared Location. </p>  <p>My custom DLL is loaded if I put in the Directory of the function itself  but is not loaded otherwise.</p>  <p>So my test function Looks like this (<a href=\""https://github.com/devkimchi/Testing-Precompiled-Azure-Functions/blob/master/PrecompiledFunctionsApp/HttpTriggerCSharp/function.json\"" rel=\""nofollow noreferrer\"">https://github.com/devkimchi/Testing-Precompiled-Azure-Functions/blob/master/PrecompiledFunctionsApp/HttpTriggerCSharp/function.json</a>):</p>  <pre><code>\""scriptFile\"": \""PrecompiledLibraries.dll\""  \""entryPoint\"": \""PrecompiledLibraries.MyHttpTrigger.Run\"" </code></pre>  <p>But since my assembly is actually located in a shared Location  I changed it to this:</p>  <p>\""scriptFile\"": \""..\\SharedLibraries\\PrecompiledLibraries.dll\""   \""entryPoint\"": \""PrecompiledLibraries.MyHttpTrigger.Run\""</p>  <p>But when I run the solution locally and watch the function using Sysinternals Procmon  I don't see the function app host to actually look for the file.</p>  <p>Specifying an absolute path doesn't work either.</p>  <p>What do I Need to specify here? Or is this an unsupported Scenario?</p>""",azure-functions
43972630,"Azure Function binding attributes - Database name setting - VS2017 preview tooling <p>I'm using the new tooling for Azure Functions projects in VS2017 Preview and have ported some functions from the Azure portal to the new projects.</p>  <p>I'm binding to an Azure Document DB - it's working fine  but when I use the <code>DocumentDB</code> attribute I have to supply the database name as the first parameter.  </p>  <p>In my case it's the DEV database for now .. but of course there will be other environments - is there a way I can pick up the database name via an application setting for the function app? </p>  <pre><code>[FunctionName(\TimerTriggeredFunction\"")] public static void Run([TimerTrigger(\""0 */5 * * * *\"")] TimerInfo myTimer  TraceWriter log                         [DocumentDB(\""my-db-DEV\""  \""MyCollection\"")]  IEnumerable&lt;dynamic&gt; inputDocuments) </code></pre>""",azure-functions
54237444,"Storage pool configuration for SQL Server <p>We are in the middle of building a new SQL Server 2017 always-on cluster in Azure VM. The data disk layout of VM are as follows</p>  <pre><code>TempDb      :   2    Azure Disk Read Cache     TempDBLog   :   1    Azure Disk No Cache     UserDB      :   3  Azure Disk   Read Cache     UserDBLog   :   2  Azure Disk   No Cache </code></pre>  <p>My plan is to create a multiple storage pool  i.e TempDB storage pool with 2 TempDB disk  UserDB storage pool with 3 User db Azure Disk.</p>  <p>However according to the link <a href=\https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/virtual-machines/windows/sql/virtual-machines-windows-sql-performance.md\"" rel=\""nofollow noreferrer\"">https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/virtual-machines/windows/sql/virtual-machines-windows-sql-performance.md</a> (First paragraph under Data Disk)</p>  <blockquote>   <p>If you are using a disk striping technique  such as Storage Spaces    you achieve optimal performance by having two pools  one for the log   file(s) and the other for the data files. However  if you plan to use   SQL Server Failover Cluster Instances (FCI)  you must configure one   pool.</p> </blockquote>  <p>Is this applicable to Always-On or just applicable to  shared storage FCI.  Please guide me  Please share good articles/docs for reference.</p>  <p>Thanks</p>""",azure-virtual-machine
43041726,Azure Web App - upload package from powershell <p>I've used <code>New-AzureRmWebApp</code> to create WebApp from <code>powershell</code>. But I don't find any <code>cmdlet</code> to upload package to created Azure Web App :( Looking for AzureRm cmdlet in specific.</p>,azure-web-app-service
56686447,Adding Application Security Group to Azure VM <p>I need to add an existing ASG (Application Security Group ) to my existing NetworkInterface.</p>  <p>In my code below I can find my ASG and NetworkInterface...  but I have no clue how to attach both of them together.</p>  <pre><code>public void AddASG(string servername  string ASGName) {     IAzure azure = ConnectAzure();     var ASG = azure.ApplicationSecurityGroups.List().Where(y =&gt; y.Name == ASGName).First();      var nic = azure.NetworkInterfaces.List()         .Where(y =&gt; y.Name.ToUpper().Contains(servername))         .Select(x =&gt; x).First();      nic.IPConfigurations?????; } </code></pre>,azure-virtual-machine
57144158,"Which way to use send messages into topic using azure function? <p>I found two ways to send messages into service bus topic from azure function.</p>  <p>one is using output - </p>  <pre><code>[FunctionName(\ServiceBusOutput\"")] [return: ServiceBus(\""myqueue\""  Connection = \""ServiceBusConnection\"")] public static string ServiceBusOutput([HttpTrigger] dynamic input  ILogger log) {     log.LogInformation($\""C# function processed: {input.Text}\"");     return input.Text; } </code></pre>  <p>Another is using code -</p>  <pre><code>const string ServiceBusConnectionString = \""string\""; const string TopicName = \""topicName\""; static ITopicClient topicClient; topicClient = new TopicClient(ServiceBusConnectionString  TopicName); string messageBody = \""Test\""; var message = new Message(Encoding.UTF8.GetBytes(messageBody)); await topicClient.SendAsync(message); </code></pre>  <blockquote>   <p>I'm not getting which one we should use and when?</p>      <ol>   <li><p>if we use <code>Output</code> how to pass queue name <code>myqueue</code> as a variable   so that in code we can assign it.</p></li>   <li><p>if i have array how can we return one by one message to output   return which will send one by one message to queue ?</p></li>   </ol> </blockquote>""",azure-functions
54838961,"How to install Root and Intermediate certificates on Azure Function app <p>I have installed both the Root and Intermediate certificates (public cer files) and also the PFX file given by the owner of the API which i am calling from within my Azure Function app. </p>  <p>Now when i call the API I am getting this error \Object contains only the public half of a key pair. A private key must also be provided.\"" </p>  <p>Any help? </p>""",azure-web-app-service
42556135,How do I get a list of TFS Collections over REST? <p>I'm working with the REST API for Team Foundation Server and Visual Studio Online. I am looking for a rest call which will tell me what collections the user has access to.</p>  <p>I cannot find a REST call which will allow me to view this information. Is there a REST call that will let me view this information for an authenticated user?</p>,azure-devops
42559740,"TFS continuous integration Basic Setup <p>This is a very basic question. I never used CI before. so please help me understand.</p>  <p>I have a MVC project (c#.net)  which i am checking into TFS online. This part works for me.</p>  <p>Now I seen companies  where when they check in  it creates a BUILD for them. This part I do not understand.</p>  <p>in my MVC project  All I want to do is...publish it to my host  so why do I want to create a build?</p>  <p>Why is build necessary? what does the build contains? its  a MVC project  so a build means a build of my MVC project (Same as I see under my \Release\"" folder\"")?</p>  <p>Can a CI publish the project to my host as well?</p>""",azure-devops
38895472,How to Install .exe file as Azure Vm Extension? <p>I am trying to create a azure virtual machine extension.The extension is .exe file.Is there any custom Method/API  to install .exe file as VM extension? </p>,azure-virtual-machine
23008095,Create a project in a subfolder in Visual Studio Online (TFS) <p>Is there any way to create a project in a subfolder in Visual Studio Online using TFVC?</p>,azure-devops
40682971,"Azure Storage Table - Insert batch of row and check if they exists <p>I sending query for some service and get back result. I want to know if I already get the same \answer\"" in the past. So  I planing to use Azure Table as a cache mechanism. </p>  <p>I making this small POC:</p>  <pre><code>TableBatchOperation batchOperation = new TableBatchOperation(); CachedUrl customer1 = new CachedUrl(Guid.Empty  \""test1\""); CachedUrl customer2 = new CachedUrl(Guid.Empty  \""test2\""); batchOperation.Insert(customer1); batchOperation.Insert(customer2); table.ExecuteBatch(batchOperation); </code></pre>  <p>When I run this code in the first time  it's working fine. At the end of this  I have 2 rows in the table. </p>  <p>The problem is in the second run. When I execute this code:</p>  <pre><code>TableBatchOperation batchOperation = new TableBatchOperation(); CachedUrl customer1 = new CachedUrl(Guid.Empty  \""test1\""); CachedUrl customer2 = new CachedUrl(Guid.Empty  \""test2\""); CachedUrl customer3 = new CachedUrl(Guid.Empty  \""test3\""); batchOperation.Insert(customer1); batchOperation.Insert(customer2); batchOperation.Insert(customer3); table.ExecuteBatch(batchOperation); </code></pre>  <p>(<em>Note</em> to the add of <code>customer3</code>)</p>  <p>What I <em>expecting to get</em> is a message that say:</p>  <ul> <li>customer1 - <em>exists</em></li> <li>customer2 - <em>exists</em></li> <li>customer3 - <em>added</em></li> </ul>  <p>What I actually get is this exception (on the <code>ExecuteBatch()</code> method):</p>  <blockquote>   <p>Request Information RequestID:5116ee8a-0002-0024-7ac1-415787000000   RequestDate:Fri  18 Nov 2016 17:33:08 GMT StatusMessage:0:The   specified entity already exists. ErrorCode:EntityAlreadyExists</p> </blockquote>  <p>The server found that the #1 entity is exist  therefore  skip the whole task.</p>  <p>How can I get the expected answer?</p>  <p>The naive solution  is to try the add all N items  one by one. But this solution is the most slow one (N HTTP requests instead 1 request). </p>""",azure-storage
57413295,"how start a python function in local which is docker enabled <p>I'm following the steps as described in the following link  <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image\"" rel=\""nofollow noreferrer\"">click here</a></p>  <p>when I'm trying to start my app with func host start  I'm getting the foll0wing error </p>  <pre><code>from google.protobuf import descriptor as _descriptor [08-08-2019 12:58:50]   File \""c:\\users\\sivasakthivelan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\google\\protobuf\\descriptor.py\""  line 47  in &lt;module&gt; [08-08-2019 12:58:50]     from google.protobuf.pyext import _message [08-08-2019 12:58:50] Exceeded language worker restart retry count for runtime:python. Shutting down Functions Host </code></pre>""",azure-functions
48567945,Where is the Azure App Service backup log <p>I have an App Service set up with a SQL database connection.  I configured the Backup setting to backup my Web App as well as the connected database  that was all very easy  and has been running well not for a couple months.  What I can't see to find is a way to get a log or report of my backup activity.  If I go to the Backups blade in Azure I see the status and my backups  but there is no way to export that list.  I've looked at the activity logs a bit and can't seem to find a way to query the backups to get the log.  Can anyone help me out with this?  I really only need a way to show the SQL database was back up  but I'm good with showing the entire App Service was back up.</p>,azure-web-app-service
54658529,"Does Azure App Service support extended ACLs? <p>I am wondering how the IP restrictions in Azure App service works. The documentation states:</p>  <p><a href=\https://docs.microsoft.com/en-us/azure/app-service/app-service-ip-restrictions\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/app-service/app-service-ip-restrictions</a></p>  <p>\""The IP Restrictions capability is implemented in the App Service front-end roles  which are upstream of the worker hosts where your code runs. Therefore  IP Restrictions are effectively network ACLs.\""</p>  <p>But they are not network ACLs  but firewall rules on a different machine - is that a valid statement? </p>  <p>Is there any way to configure extended ACLs (with port based rules) if that is not the case?</p>""",azure-web-app-service
47410712,"Managed Disks - Delete source blob? <p>I have a Windows VM that was built on the old \classic\"" model which I would like to change to the ARM model. I have used the automated methods however this doesn't give me the control I desire (the names of all the components are messy).</p>  <ul> <li>I have deleted the original VM leaving only the VHD in the storage account.</li> <li>I have created a Managed Disk (MD) using the VHD as the source blob.</li> <li>I have created a VM using the MD</li> </ul>  <p>When I look at the MD in the Azure portal  it still references the \""Source Blob\"" but i'm not sure if this means the MD is still reliant on the blob and storage account or if it's just legacy/reference info.</p>  <p>What I need to know is  can I delete the original storage account containing the VHD now that I have a MD?</p>""",azure-virtual-machine
48901735,"How do I authenticate an npm registry from inside a Docker container in VSTS? <p>I have a Docker Compose build task build out a Node.js project on VSTS. Because we're moving to a private npm registry on VSTS  this means the Docker container needs a way to authenticate with the registry to download packages.</p>  <p><strong>Is there a way to send VSTS credentials to the Docker container so when it builds  it has access to the private npm registry?</strong></p>  <p>I thought of hard-coding VSTS's generated npm credentials into the project's <code>.npmrc</code> file  but even in that case  it wouldn't build in VSTS giving me a <em>\401 Unauthroized\""</em> when doing <code>yarn install</code>:</p>  <blockquote>   <p>An unexpected error occurred: \""<a href=\""https://[VSTS_NAME].pkgs.visualstudio.com/_packaging/[REGISTRY_NAME]/npm/registry/ajv/-/ajv-6.1.1.tgz\"" rel=\""nofollow noreferrer\"">https://[VSTS_NAME].pkgs.visualstudio.com/_packaging/[REGISTRY_NAME]/npm/registry/ajv/-/ajv-6.1.1.tgz</a>: Request failed \\\""401 Unauthorized\\\""\"".</p> </blockquote>""",azure-devops
39135191,How does Azure web app deployment works after swapping? <p>I have an ASP.NET MVC application deployed to a standard Azure web app service. I also configure the web app to have 1 deployment slot called 'staging'. First  I published my web app using VS2015 publishing tool to staging slot and tested. It worked so I swapped it with production slot. Then  I published another version with some code changes to staging slot again. It published directly to my production slot. I thought Azure web app production slot is now actual staging slot after swapping. How can I make the web app always publish to the slot that is not currently live (i.e. production slot) to test before swapping again?</p>  <p>I published the web app by right click on the web project and select publish  enter my azure subscription ID and password  select web app and publish.</p>  <p>Thank you</p>,azure-web-app-service
16210861,"ERROR_DESTINATION_INVALID on publishing my web site on Windows AZURE <p>I have created an ASP.NEt WEB API. I want to host this on Windows AZURE. I have successfully created the website on Windows Azure and downloaded the Publish Settings files for it.Now when I publish my Web API from VS-2012 on Windows 8 machine it asks me to import the publish settings file that i have recently downloaded. I provided it that file and when i click on the \Validate Connection\"" button it is failed. It is giving following errors.</p>  <p><img src=\""https://i.stack.imgur.com/00BKK.png\"" alt=\""enter image description here\""> <img src=\""https://i.stack.imgur.com/S3eh2.png\"" alt=\""enter image description here\""></p>  <p>I want to mention that I am behind a corporate firewall and using a proxy connection. If it is related to Firewall or Proxy then please tell me that what can I change to my Firewall / Proxy settings to make it working.</p>  <p>Thanks in Advance...</p>""",azure-web-app-service
39369937,"Azure Web App with \https\"" url to Azure App Api request not working <p>Angularjs http request to external Azure App Api fails from Azure Web App with \""https\""  but works when url is http.  Authentication is turned on in Web App  but requires no action if not authenticated.  What am I missing?</p>""",azure-web-app-service
53365449,OData Client App Authentication with Azure App Service Example <p>Is there an example of a external OData client using AAD to access an Azure App Service acting as a OData server? The identity being provided is of the client app itself registered as a native app in AAD  not the user  so no user authentication interface is needed in the app.</p>,azure-web-app-service
21085749,TFS for Microsoft Excel files <p>I am using Team Foundation Services (TFS 2012) for development projects.</p>  <p><em>I want to know if TFS can be used for version-control of Excel files?</em></p>  <p>Specifically:</p>  <ul> <li>I need to commit changes; Is this done within Excel or externally? How?</li> <li>I need to resolve conflicts; Is this done within Excel or externally? How?</li> <li>I need to compare my current Excel document changes vs. the Original in Source control; Is this done within Excel or externally? How?</li> </ul>,azure-devops
50277986,Azure Functions V1 linking wrong version of the RestSharp.dll <p>Guys I know that the azure functions cli has a dependency with RestSharp.dll and I think that is conflicting with one of my Azure Functions.</p>  <p>I am getting a runtime type exception System.TypeLoadException: 'Could not load type 'RestSharp.IAuthenticator' from assembly 'RestSharp  Version=105.2.3.0  Culture=neutral  PublicKeyToken=null'.'</p>  <p>Now my azure function is dependent on RestSharp nuget Version 104.4.0.0. There is no reference in my project to Version 105.2.3.0.  Here is the interesting thing. In my despair I searched my entire computer for the culprit dll version 105.2.3.0 and I found it at AppData\local\Azure.Functions.Cli\1.0.12</p>  <p>Is that it ? Is the Azure functions runtime trying to link with its  RestSharp.dll version instead of the dll version of my project ?</p>,azure-functions
57257127,"Obtaining host url from Azure Web App with Gateway listener <p>I've a Web App that's running on ASP.NET Core with SwaggerUI. For the UI I need to add the host url in order to have a complete json blueprint that can be loaded into Postman. Before the App Gateway I was able to get the host url the following way:</p>  <pre class=\lang-cs prettyprint-override\""><code>swaggerDoc.Host = httpReq.Host.Value; </code></pre>  <p>Now there's an App Gateway placed infront of it with its own hostname. The above method however only allows me to get the backend pool hostname. Is there any way to retrieve the hostname from the App Gateway?</p>""",azure-web-app-service
37727720,"Linux Azure VM web server not accesible <p>I have created a resource management VM  installed nginx and can't seem to access it from outside  did an ip forward from the options  also set up a static DNS  can't seem to find a solution.</p>  <p>Inbound / Outbound http 80 allowed.</p>  <p>Tested localhost with wget and works.</p>  <p><a href=\http://i.stack.imgur.com/xlaEz.jpg\"" rel=\""nofollow\"">Wget localhost / IP Forward</a></p>  <p><a href=\""http://i.stack.imgur.com/I76tb.jpg\"" rel=\""nofollow\"">Inbound / Outbound rules</a></p>""",azure-virtual-machine
31963192,How to backup Azure VM in Resource Group? <p>Is is possible to backup or take a snapshot of a VM created with the Azure preview portal in a Resource Group (not classic/CloudService-based ones)? These new VMs are not visible from the old portal  so I cannot use Azure Backup  and the VM blade does not show any option to capture it/take a snapshot.</p>,azure-virtual-machine
38184202,"Post App Service Migration - Create Table Error <p>Having recently migrated my Azure Mobile Service to the Azure App Service platform I've noticed that I am now unable to create new tables?</p>  <p>I have created the tables through the SQL Server Management Studio  the same as I was doing previously with my Mobile Service  and then just adding the table as a 'New Table' within the Mobile Service. This used to pull the table I had created in that schema into the Mobile Service and make it accessible.</p>  <p>However  since going to App Services I have tried to do the same thing but get the following error:</p>  <blockquote>   <p>Table creation error! There was an error while creating table 'Items'.   '{   \Message\"": \""An error has occurred.\""    \""ExceptionMessage\"": \""The   specified schema name \\\""<strong>SCHEMANAME</strong>\\\"" either does not exist or you   do not have permission to use it.\""    \""ExceptionType\"":   \""System.Data.SqlClient.SqlException\""    \""StackTrace\"": \""   at   System.Data.SqlClient.SqlConnection.OnError(SqlException exception    Boolean breakConnection  Action`1 wrapCloseInAction)\\r\\n   at ......</p> </blockquote>  <p>To fix this I've tried changing the <code>MobileAppsManagement_EXTENSION_VERSION</code> to 'beta' from 'latest' which is apparently the MS Fix:  <a href=\""https://www.gittprogram.com/question/32407_unable-to-create-new-table-since-migrated-azure-mobile-services-to-app-service.html\"" rel=\""nofollow\"">https://www.gittprogram.com/question/32407_unable-to-create-new-table-since-migrated-azure-mobile-services-to-app-service.html</a></p>  <p>I Tried this but had no joy. Also checked to see if a new instance had been created in the move but I couldn't find anything suspicious...Any ideas?</p>  <p>Many thanks</p>""",azure-web-app-service
19454647,VPN PPTP Limitations with Azure Virtual Machines <p>We're evaluating Azure Virtual Machines for a data warehousing project and have found that it doesn't support PPTP VPN connecting from the VM to an on-premise network.</p>  <p>We need to connect to an on-premise source SQL server that's behind an older router and have found that if it's not an Azure supported router  it won't work.  Additionally  Azure's Virtual Network functionality took a day just to decipher.</p>  <p>We'd expect simple VPN functionality from the VM to work  but apparently Microsoft is blocking the required protocols so that Virtual Networking has to be used.</p>  <p>This configuration works fine from EC2 and even from my laptop.  We would have preferred Azure since we have a SQL server architecture  though if this limitation is true  we'll have to move to EC2 from Azure.</p>  <p>Has anyone run into this or can someone confirm there is no workaround?</p>,azure-virtual-machine
46055830,Let's Encript SSL Certificate and Azure Traffic Manager <p>I am trying to use <code>Azure Traffic Manager</code> to load balance traffic between a website hosted on an <code>Azure VM</code> in 2 different regions (Europe and US).</p>  <p>The <code>Azure Traffic Manager</code> is setup happily with the DNS name <code>mywebsite.trafficmanager.net</code></p>  <p>I have 2 end points setup with dns names <code>mywebsite-uk.uksouth.cloudapp.azure.com</code> and <code>mywebsite-us.westus.cloudapp.azure.com</code></p>  <p>In order to setup a vanity domain I have a <code>CNAME</code> record pointing to </p>  <pre><code>www.mywebsite.trafficmanager.net </code></pre>  <p>When I go to <code>http://mywebsite.trafficmanager.net</code> or <code>www.mydomain.com</code> I get correctly routed to the closest site.</p>  <p>Unfortunately I am struggling when I try to get <code>HTTPS / SSL</code> working. I am attempting to use Let's Encrypt via the Certify SSL Certificate Management tool to issue an SSL certificate to each of the servers however I am getting the following error:</p>  <pre><code>Validation of the required challengers did not complete successfully. Please ensure all domains to be referenced in the Certificate can be used to access this site without redirection. </code></pre>  <p>I have created bindings in <code>IIS</code> for both <code>mywebsite-uk.mydomain.com</code> and <code>www.mydomain.com</code>  and an A record for <code>mywebsite-uk</code> to the ip of the web server and whenever I request a certificate that includes <code>www.mydomain.com</code> I get the error.</p>  <p>Has anyone got an experience with this type of setup? and more importantly any advice on what I am doing wrong? Would I be better biting the bullet and getting a paid for SSL certificate?</p>  <p>Many thanks in advance </p>,azure-virtual-machine
46542189,Deploying python machine learning model using Azure Functions <p>I developed a machine learning model locally and wanted to deploy it as web service using Azure Functions.</p>  <p>At first model was save to binary using pickle module and then uploaded into blob storage associated with Azure Function (python language  http-trigger service) instance.  </p>  <p>Then  after installing all required modules  following code was used to make a predicition on sample data:</p>  <pre><code>import json import pickle import time  postreqdata = json.loads(open(os.environ['req']).read())  with open('D:/home/site/wwwroot/functionName/model_test.pkl'  'rb') as txt:     mod  = txt.read() txt.close()  model = pickle.loads(mod) scs= [[postreqdata['var_1'] postreqdata['var_2']]]  prediciton = model.predict_proba(scs)[0][1]  response = open(os.environ['res']  'w') response.write(str(prediciton)) response.close() </code></pre>  <p>where: <strong>predict_proba</strong> is a method of a trained model used for training and <strong>scs</strong> variable is definied for extracting particular values (values of variables for the model) from POST request. </p>  <p>Whole code works fine  predictions are send as a response  values are correct but the execution after sending a request lasts for 150 seconds! (locally it's less than 1s). Moreover  after trying to measure which part of a code takes so long: it's 10th line (pickle.loads(mod)).</p>  <p>Do you have any ideas why it takes such a huge amount of time? Model size is very small (few kB).</p>  <p>Thanks</p>,azure-functions
54764018,"struggling with \did you forget to signal async completion?\"" <p>I know  this can be duplicate question  but i have almost spend 1 day to make it working. </p>  <p>so  i have gulpfile.js like here</p>  <pre><code>const gulp = require('gulp'); const javascriptObfuscator = require('gulp-javascript-obfuscator'); gulp.task(\""javascriptObfuscator\""  (done) =&gt; {     gulp.src('./js/**/*.js'  {base: './'})         .pipe(javascriptObfuscator())         .pipe(gulp.dest('./'))         done();  }); </code></pre>  <p>so when i'm running this file in azure pipeline under \""Gulp task\""  facing this error \""did you forget to signal async completion?\""</p>""",azure-devops
35459549,"Azure Powershell Script: Parse Error <p>Trying to setup a new VM via PowerShell. Works fine when I copy &amp; paste commands step by step to PowerShell ISE but  fails when I try to run them in one rush. </p>  <p>I have removed other parts of the script  it is also failing with only this lines:</p>  <pre><code>$VM_NAME         = \VMNAME\"" $VM_SIZE         = \""Small\"" $VM_IMAGE        = \""5112500ae3b842c8b9c604889f8753c3__OpenLogic-CentOS-71-20150605\"" $LOCATION        = \""West Europe\"" $STORAGE_ACCOUNT = \""disktest\"" $CLOUD_SERVICE   = \""disktest\"" $SSH_USER        = \""azureuser\"" $SSH_PASSWORD    = \""324w##eANC\"" $VIRTUAL_NETWORK = \""Playground\"" $SUBNET          = \""P\""  $BOOTSTRAP_CHEF      = $FALSE $PATH_PUBLIC_CONFIG  = \""publicconfig.json\"" $PATH_PRIVATE_CONFIG = \""privateconfig.json\"" $DISK_CREATE         = $TRUE $DISK_SIZE           = 500 $DISK_COUNT          = 2 $DISK_LABEL          = \""datadisk\"" $DISK_LUN            = 0 $REMOVE_SSH_ENDPOINT = $FALSE $HTTP_ENDPOINT       = $FALSE $SHUTDOWN            = $FALSE  Select-AzureSubscription -SubscriptionName \""SUB\"" -Current;  if (!(Test-AzureName -Storage $STORAGE_ACCOUNT)) {     New-AzureStorageAccount -StorageAccountName $STORAGE_ACCOUNT -Location $LOCATION }  if (!(Test-AzureName -Service $CLOUD_SERVICE)) {     New-AzureService -ServiceName $CLOUD_SERVICE -Location $LOCATION }  Set-AzureSubscription -SubscriptionName \""SUB\"" -CurrentStorageAccountName $STORAGE_ACCOUNT  $existing = Get-AzureVM -ServiceName $CLOUD_SERVICE -Name $VM_NAME </code></pre>  <p>Error message:</p>  <pre><code>In Zeile:36 Zeichen:1 + $existing = Get-AzureVM -ServiceName $CLOUD_SERVICE -Name $VM_NAME + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ AusfÃ¼hrbarer Skriptcode wurde im Signaturblock gefunden.     + CategoryInfo          : ParserError: (:) []  ParentContainsErrorRecordException     + FullyQualifiedErrorId : TokenAfterEndOfValidScriptText </code></pre>  <p>If i first set the variables  remove them from script window  and run again it works like a charm.</p>""",azure-virtual-machine
53781863,"How to change who a Pull Request is assigned to <p>I want to change who is assigned to a pull request.  I created the pull request  but I want to change it to someone else.  Can I do that in Azure DevOps?</p>  <p><a href=\https://i.stack.imgur.com/wl9ui.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/wl9ui.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
14949572,"Shared Umbraco Media Folder on Azure Cloud Instances <p>I have just implemented Umbraco in an Azure Cloud Instance. I was able to migrate my existing SQL Database to run on SQL Azure and everything runs fine  except for the images and documents inside the media folder. </p>  <p>By default the media folder resides in [siteroot]/Media. </p>  <p>Is there a way to map this folder to azure storage? If not I don't think I'm going to be able to scale up my cloud instances  since the images depend on the virtual server's local storage.</p>  <p><strong>Edit: Bounty Started</strong></p>  <p>What I have so far is this:</p>  <ul> <li>Define a stand alone web role which would hold the media directory and all the files. </li> <li>Map this folder to the Azure Blobg Storage service with Cloud Drive  in order to minimize the risk of losing data and relying on a single point of storage. </li> <li>Somehow (and this is the part I don't know how to accomplish) keep all the folder of [siteRoot]/media synced with this shared drive on all running instances.</li> </ul>  <p>I've seen a similar approach taken with the Azure Accelerator project from Umbraco here: <a href=\http://azureaccelerators.codeplex.com/releases\"" rel=\""nofollow\"">http://azureaccelerators.codeplex.com/releases</a></p>  <p>But they haven't updated the release since 2011  and I'm not sure it would work with the current version of Azure. </p>  <p><strong>Edit 2:</strong></p>  <p>Umbraco has their own accelerator  but they've deprecated it in favor of using Websites instead of Web Roles: <a href=\""https://github.com/Microsoft-DPE/wa-accelerator-umbraco\"" rel=\""nofollow\"">https://github.com/Microsoft-DPE/wa-accelerator-umbraco</a></p>  <p>This release works with the 1.6 SDK. Current version is 1.8 I believe...</p>""",azure-storage
49075111,"Simple Azure Function in Javascript to use HTTP trigger body in queue <p>So I'm messing about with <a href=\https://docs.microsoft.com/en-us/azure/sql-data-warehouse/manage-compute-with-azure-functions\"" rel=\""nofollow noreferrer\"">Use Azure Functions to automate SQL DW compute level</a> from the MS website... and I've created a HTTP trigger that will send a msg to the queue when hit. I'm very new to Javascript  and I'm wondering how to use the HTTP request 'body' in place of the variable I have below</p>  <pre><code>module.exports = function (context  res ) {     var timeStamp = new Date().toISOString();     context.log('JavaScript timer trigger function ran!'  timeStamp);        context.res = { status: 201  body: \""Resuming Datawarehouse\"" };        var operation = {         \""operationType\"": \""ResumeDw\""     }     context.bindings.operationRequest = operation;     context.done(null  res); }; </code></pre>  <p>Quite simply  I willy have some JSON in my HTTP request body that will hit this trigger  I then want to use only what's in that body for my queue. In this case above  it would replace <code>var operation =</code></p>  <p>Any ideas  please?</p>  <p>Just an FYI  I want it to replace what I already have:</p>  <pre><code>    var operation = {         \""operationType\"": \""ResumeDw\""     }     context.bindings.operationRequest = operation; </code></pre>  <p>This is static inside the Function  but I want whatever the HTTP request sends as its body to be sent to my queue.</p>""",azure-functions
19425442,"Delete project from Visual Studio Team Services (from a mac) <p>Similar to this questions: <a href=\https://stackoverflow.com/questions/15961041/delete-project-from-tfs-online-with-vs2010-professional-tfsdeleteproject-isnt\"">Delete project from TFS online with VS2010 Professional (TFSDeleteProject isn&#39;t on my computer!)</a></p>  <p>Except in this instance  I'm using the Git feature of tfs online for code versioning and using a mac. I suppose I could setup a virtual machine and install Team Explorer  but that seems like a bit of a hassle. I'm just curious if anyone else has a suggestion on how else I could delete the project?</p>""",azure-devops
46467695,how updates happen when I add my VMs to DSC and availability sets <p>If I add two of my VMs to desired state configuration(DSC) nodes with same DSC configuration and add those two VMs to a single availability set with update domains=2  how the updates will happen to those VMs? Will the updates happen at a time or one after the other?</p>  <p><strong>Note:</strong> Assume I made some software updates or enabled some features in windows through my powershell script.</p>,azure-virtual-machine
27851131,Azure Edit blob <p>I have various file types that are uploaded into blob storage.  I am needing to edit/read these files using third party tools (Exiftool  Imagemagick  etc. - I know I could possibly use the Media Services but I am required to use these tools).  Once the files are in blob storage does my worker role have to download the blob from storage in order to work with the file?  The reason for the questions is that I am working with very large files (videos  images  etc.) and I don't necessarily want to use MemoryStream.</p>  <p>If I have to download the file from storage into let's say a temporary folder  what is the performance hit and are there any other options for editing/reading the file?</p>,azure-storage
48442849,Azure App Service - call to VNET service is not working <p>I have a App service which is in VNET1 and this VNET1 is connected to VNET2 on other network with Point-to-Site Connection. My App Service is connected to VNET1.</p>  <p>These two VNETs are connected and tested. those are working fine.</p>  <p>when i ping (tcpping) from App Service console to VNET1 and VNET2 IP its working fine. Also <code>Curl</code> Request is working fine.</p>  <p>But when i call the Same URL from App service page. its showing Request Time out Error. </p>  <p>Any Suggestions why this is not working?</p>,azure-web-app-service
10908830,"Azure storage  can not upload images correctly <p>I am trying to create a action  in a mvc project. that can upload files and images to my azure storage. but for some reason will it just not upload corrently  that is what i am guessing. If i upload the image with \Azure Storage Explorere\"" dose it work fine. Example: <a href=\""http://storage.sogaard.us/company1/wallpaper-396234.jpg\"" rel=\""nofollow\"">http://storage.sogaard.us/company1/wallpaper-396234.jpg</a> But if i try to upload the image though my action will it not work  it send a 200 for succes and the right conten type  but the image will not load  and my developer tool tells me i got not data from the server. Example: <a href=\""http://storage.sogaard.us/company1/b9206edac188e1d8aa2b3be7cdc4b94a.jpg\"" rel=\""nofollow\"">http://storage.sogaard.us/company1/b9206edac188e1d8aa2b3be7cdc4b94a.jpg</a></p>  <p>I have tried to save the uploaded til to my local computer instead of the azure storage and it worked fine there! I can simply not find the reason and this have been bugging me all day :(</p>  <p>Here is my code</p>  <pre><code>[HttpPost] public ActionResult Upload(FilesUploadModel model  IEnumerable&lt;HttpPostedFileBase&gt; files) {      if(ModelState.IsValid)     {         if (files != null &amp;&amp; files.Any())         {             int maxSizeInBytes = ConfigurationManager.Instance.Configuration.FileMaxSize;             Size thumbSize = new Size(200  200);              foreach (HttpPostedFileBase file in files.Where(x =&gt; x != null))             {                 CMS.Common.Data.File _file = new Sogaard.Inc.CMS.Common.Data.File();                  // is any files uploadet?                 if (!(file.ContentLength &gt; 0))                 {                     FlashHelper.Add(Text(\""File not received\"")  FlashType.Error);                     continue;                 }                 // is the file larger then allowed                 if (file.ContentLength &gt; maxSizeInBytes)                 {                     FlashHelper.Add(Text(\""The file {0}'s file size was larger then allowed\""  file.FileName)  FlashType.Error);                     continue;                 }                  var fileName = Encrypting.MD5(Path.GetFileNameWithoutExtension(file.FileName) + DateTime.Now) + Path.GetExtension(file.FileName);                 string mimeType = FileHelper.MimeType(FileHelper.GetMimeFromFile(file.InputStream));                  _file.SiteId = SiteId();                 _file.Container = GetContainerName();                 _file.FileName = Path.GetFileName(file.FileName);                 _file.FileNameServer = fileName;                 _file.Created = DateTime.Now;                 _file.Folder = model.Folder;                 _file.Size = file.ContentLength;                 _file.Type = mimeType;                  if (mimeType.ToLower().StartsWith(\""image/\""))                 {                     try                     {                         // So we don't lock the file                         using (Bitmap bitmap = new Bitmap(file.InputStream))                         {                             _file.Information = bitmap.Width + \""|\"" + bitmap.Height;                              if (bitmap.Height &gt; 500 &amp;&amp; bitmap.Width &gt; 500)                             {                                 var thumbfileName = Encrypting.MD5(Path.GetFileNameWithoutExtension(file.FileName) + \""thumb\"" + DateTime.Now) + \"".jpeg\"";                                 Size thumbSizeNew = BaseHelper.ResizeImage(bitmap.Size  thumbSize);                                 Bitmap thumbnail = (Bitmap)bitmap.GetThumbnailImage(thumbSizeNew.Width                                                                                            thumbSizeNew.Height                                                                                            ThumbnailCallback                                                                                            IntPtr.Zero);                                 _file.ThumbFileNameServer = thumbfileName;                                 // Retrieve reference to a blob named \""myblob\""                                 CloudBlob blob = container().GetBlobReference(_file.ThumbFileNameServer);                                 blob.Metadata[\""Filename\""] = Path.GetFileNameWithoutExtension(file.FileName) + \""-thumb\"" + \"".jpg\"";                                 blob.Properties.ContentType = \""image/jpeg\"";                                  // Create or overwrite the \""myblob\"" blob with contents from a local file                                 using (MemoryStream memStream = new MemoryStream())                                 {                                     thumbnail.Save(memStream  ImageFormat.Jpeg);                                     blob.UploadFromStream(memStream);                                 }                                 blob.SetMetadata();                                 blob.SetProperties();                             }                         }                     }                     catch (Exception e)                     {                         if (e.GetType() != typeof (DataException))                             FlashHelper.Add(Text(\""The image {0} was not a valid image\""  file.FileName)                                              FlashType.Error);                         // Removing the file                         System.IO.File.Delete(file.FileName);                     }                 }                 else                 {                     _file.Information = null;                 }                 // Retrieve reference to a blob named \""myblob\""                 CloudBlob blobF = container().GetBlobReference(fileName);                 blobF.Metadata[\""Filename\""] = file.FileName;                 blobF.Properties.ContentType = mimeType;                  // Create or overwrite the \""myblob\"" blob with contents from a local file                 blobF.UploadFromStream(file.InputStream);                 blobF.SetMetadata();                 blobF.SetProperties();                  fileService.Save(_file);             }         }          return RedirectToAction(\""Display\""  new { Folder = model.Folder });     }      model.FolderSugestion = fileService.GetFolders(SiteId());     return View(model); }      private CloudBlobContainer container()     {         // Retrieve storage account from connection-string         CloudStorageAccount storageAccount = CloudStorageAccount.Parse(             RoleEnvironment.GetConfigurationSettingValue(\""StorageConnectionString\""));          // Create the blob client         CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();          // Retrieve reference to a previously created container         var container = blobClient.GetContainerReference(GetContainerName());         container.CreateIfNotExist();         return container;     }      private string GetContainerName()     {         return \""company\"" + SiteId();     } </code></pre>""",azure-storage
41346736,"Web app onboarding to Azure Web Marketplace <p>We checked this documentation - <a href=\https://blogs.msdn.microsoft.com/appserviceteam/2016/08/26/onboarding-to-azure-web-marketplace\"" rel=\""nofollow noreferrer\"">https://blogs.msdn.microsoft.com/appserviceteam/2016/08/26/onboarding-to-azure-web-marketplace</a> on how to onboard our web apps in the Azure marketplace and also the GitHub link - <a href=\""https://github.com/SunBuild/web-app-marketplace\"" rel=\""nofollow noreferrer\"">https://github.com/SunBuild/web-app-marketplace</a></p>  <p>We have contacted MSFT on how to host our application which has an API and WCF applications as sub-applications.</p>  <p>MSFT replied that sub applications are not currently supported in through this onboarding model.</p>  <p>So  we are trying to onboard the three applications individually and link them in the Azure marketplace. We are not sure whether this will work or if this is possible.</p>  <p>In the sample applications in the GitHub link - <a href=\""https://github.com/SunBuild/web-app-marketplace\"" rel=\""nofollow noreferrer\"">https://github.com/SunBuild/web-app-marketplace</a>  they have a hosting plan JSON file for the web app resource. Can we link the applications using this hosting plan JSON file?</p>  <p>We could not find any information or definition related to this hosting plan file - <a href=\""https://github.com/SunBuild/web-app-marketplace/blob/master/WebApp-SQLDatabase/DeploymentTemplates/Website_NewHostingPlan_SQL_NewDB-Default.json\"" rel=\""nofollow noreferrer\"">https://github.com/SunBuild/web-app-marketplace/blob/master/WebApp-SQLDatabase/DeploymentTemplates/Website_NewHostingPlan_SQL_NewDB-Default.json</a></p>  <p>Does anyone tried this before or know how to do this?</p>""",azure-web-app-service
50332824,Stream File in Azure App Service lost bytes <p>I have a very unusual problem in when I try to Stream file with ASP.NET core and ASP.NET full framework.</p>  <p>I have been trying with  different code samples which work in my local environment and in my local IIS 7. However these code samples when executed in an App Service does not work well. It is impossible to download a  complete file. In every execute  my file(s) lose  a few bytes resulting in corrupted files (upon download).</p>  <p>As I have tried multiple code samples am not providing the code snippets here.The code samples were picked up from either stackoverflow or official documentation.</p>,azure-web-app-service
41768881,"Can I Pass MSDeploy Parameters to Azure Web App MSDeploy Extension? <p>There is an MSDeploy extension available for Azure Web Apps; this can be used with Azure Resource Manager (ARM) Templates as well (<a href=\https://github.com/davidebbo/AzureWebsitesSamples/blob/master/ARMTemplates/WordpressTemplateWebDeployDependency.json\"" rel=\""nofollow noreferrer\"">example</a>).  I'd like to pass additional command-line arguments to MSDeploy  such as -enableRule:AppOffline (<a href=\""https://github.com/davidebbo/AzureWebsitesSamples/blob/master/ARMTemplates/WordpressTemplateWebDeployDependency.json\"" rel=\""nofollow noreferrer\"">example</a>).</p>  <p>Is there documentation for the MSDeploy Web App extension for passing additional arguments  etc.?</p>""",azure-web-app-service
54936239,"Where to find output of tests using Console.write in Azure Pipeline <p>I've create a build pipeline for C# in Azure DevOps and it builds and executes the tests properly. What I'm searching for is where to find the output of my custom output that I create using Console.Writeline. An example of the statement I use is:</p>  <pre><code>Console.WriteLine(\Found optimal value {0} in {1} seconds. Max Time allowed: {2} seconds.\""  var1.ToString()  var2.ToString  var3.ToString()); </code></pre>  <p>The entry in my yaml file for the build pipeline is:</p>  <pre><code>- task: VSTest@2   inputs:     platform: '$(buildPlatform)'     configuration: '$(buildConfiguration)'     collectDumpOn: always </code></pre>""",azure-devops
44503675,SQL Service Broker in Azure VM <p>I have enabled the Service Broker in the Azure VM running Windows Server and with a SQL Server installed. The problem althought it looks like the service is running  it does not trigger a notification back to the IIS Website via the '<code>SqlDependecy</code>'. Note that this work in the Development PC  but in the Azure VM not sure why not  what can be preventing the notification to being triggered?</p>  <p>Tried:</p>  <pre><code>SELECT * FROM sys.service_queues -- ok SELECT is_broker_enabled FROM sys.databases WHERE name = 'Database_name'; -- ok ALTER AUTHORIZATION ON DATABASE::[Database_name] TO [sa] -- no difference SELECT transmission_status  * FROM sys.transmission_queue -- empty </code></pre>,azure-virtual-machine
44633705,Azure Blockchain as a Service port's config <p>I am using Blockchain as a Service on Azure to deploy a private blockchain.</p>  <p>The default ports are <code>8545</code> for the <code>RPC ENDPOINT</code> and <code>3000</code> for the first transaction node. I would like to change these parameters because of a firewall constraint. </p>  <p>Is it possible and how can I do it? </p>,azure-virtual-machine
46747585,Delete Azure table from storage programatically c# but not manually <p>Is there a way we do not allow users to delete tables manually by connecting to azure table storage instead allow the c# code to delete it programmatically. This will restrict users accessing the shared table storage from deleting tables.</p>,azure-storage
56462813,Instance type equivalent to AWS m4.2xlarge in Azure <p>I need an Azure instance in balance of compute  memory  and network resources  same as m4.2xlarge in AWS.  Which instance type would provide good results in Azure?</p>  <p>I have already tried spinning up three different instances for compute(Standard F2s)  memory(Standard DS11-1_v2) and network(Standard D2s v3) in Azure  but have been facing too much of timeout in between the instance communication. </p>  <p>In parallel have tested the complete setup in AWS m4.2x.large instance  which has given pretty good result.</p>  <p>Hence now I want to configure all my modules in one single instance and check results.</p>,azure-virtual-machine
35365523,"How to remove \bootdiagnostics\"" container from storage blob when deleting Azure VM? <p>I'm tasked with automating the creation of Azure VM's  and naturally I do a number of more or less broken iterations of trying to deploy a VM image.</p>  <p>I just discovered that my storage account's blob service is collecting a looong list of containers for boot diagnostics.</p>  <p>Because I've deleted many of the VM's these belong to  these containers are all useless to me  and in the portal they crowd out the few useful folders I do want. In fact  I have a script to destroy VM's (which removes the resources  VHD  and so on); I want this script to also kill these diagnostics containers.</p>  <p>But the containers have very awkward names -- and only contain part of the hostname ...</p>  <ul> <li>How can I  from Powershell  identify the diagnostics container belonging to a specific VM  so that I can delete it along with the other resources?</li> <li>Why does Azure not handle this more elegantly  why do I have to \""discover\"" that diagnostics containers and VHD's are not removed when you remove a VM? Is there simply yet another button or screen that I'm not aware of?</li> </ul>  <p><a href=\""https://i.stack.imgur.com/pvWQg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/pvWQg.png\"" alt=\""enter image description here\""></a></p>""",azure-storage
55030699,How to completely replace master with another branch in Azure DevOps <p>Using Azure DevOps  there is a repo with valid code being maintained in a secondary branch. However  the master branch is multiple years out of date.</p>  <p>I want to obliterate the contents of master and overwrite it with the contents of the secondary branch.</p>  <p>I understand that mishandling this can cause serious namespaces issues and I would like to avoid that.</p>  <p>What method would you recommend for completely replacing master with a secondary branch in Azure DevOps?</p>,azure-devops
45624855,"Azure Function Output Service Bus Binding From Timer trigger <p>I am running Visual Studio 2017 Preview and running the function code locally and I am using the out of the box Azure Function project template. I'm trying to have an Azure Function triggered by a timer send a message to a Service Bus queue using an output binding but it looks like the WebJob SDK can't bind the output to a string type.  </p>  <p><strong>Binding</strong></p>  <pre><code> \bindings\"": [     {       \""type\"": \""serviceBus\""        \""name\"": \""msg\""        \""queueName\"": \""myqueue\""        \""connection\"": \""ServiceBusQueue\""        \""accessRights\"": \""manage\""        \""direction\"": \""out\""     }   ] </code></pre>  <p><strong>Timer Function</strong></p>  <pre><code>using System; using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Host;  namespace MyFunctionApp {     public static class TimerTrigger     {         [FunctionName(\""TimerTriggerCSharp\"")]         public static void Run([TimerTrigger(\""1 * * * * *\""  RunOnStartup = true)]TimerInfo myTimer  TraceWriter log  out string msg)         {             log.Info($\""C# Timer trigger function executed at: {DateTime.Now}\"");              msg = \""Hello!\"";         }     } } </code></pre>  <p><strong>Error Message</strong></p>  <blockquote>   <p>TimerTriggerCSharp: Microsoft.Azure.WebJobs.Host: Error indexing   method 'Functions.TimerTriggerCSharp'. Microsoft.Azure.WebJobs.Host:   Cannot bind parameter 'msg' to type String&amp;. Make sure the parameter   Type is supported by the binding. If you're using binding extensions   (e.g. ServiceBus  Timers  etc.) make sure you've called the   registration method for the extension(s) in your startup code (e.g.   config.UseServiceBus()  config.UseTimers()  etc.).</p> </blockquote>  <p>Am I missing a step in the setup  or does the Service Bus binding really not support a string for an <code>out</code> parameter</p>""",azure-functions
30297014,"Azure Table Storage Doesn't Save Everything in Entity definition <p>This is the same of the entity that I am planning to save in the Azure Table Storage (ATS):</p>  <pre><code>public class CarEntity : TableEntity {      public CarEntity(string objPartitionKey  string objRowKey)     {         this.PartitionKey = objPartitionKey;         this.RowKey = objRowKey;     }      public string TableName     {         get { return \EntityTableName\""; }     }      public string Property1 { get; set; }     // and this goes on     public string Property60 { get; set; } } </code></pre>  <p>Not all properties are required. Population of records depend on the selections that the user would be saving (e.g this is a CarEntity - if the user ordered wheels  properties WheelSize and WheelQuantity would be populated  if the user asks for repainting  RepaintingColor would be populated and so  on). </p>  <p>Assuming that there are 60 properties in this entity  not all properties gets saved in ATS. Despite a property being defined and no error being returned  that data doesn't get saved in the table. I know that there's a limit of 1MB per entity but considering the computations that we have done  it is kinda far from the 1MB limit. </p>  <p>Any help why columns don't appear even if the properties are saved accordingly? My save function is defined as follows:</p>  <pre><code>    public static CarEntity CarInsertOrReplace(CarEntity entity)             {         if (entity == null)         {             throw new ArgumentNullException(\""entity\"");         }          var table = SetupTable(entity.TableName);         table.CreateIfNotExists();          TableOperation insertOrMergeOperation = TableOperation.InsertOrReplace(entity);          TableResult result = table.Execute(insertOrMergeOperation);         CarEntity objEntity = result.Result as CarEntity;         return objEntity;     } </code></pre>""",azure-storage
47693396,"Can't connect to \Jenkins-On-Azure\"" <p>I created a Jenkins linux vm on Azure on a new resource group.</p>  <p>I followed the steps described here:  <a href=\""https://docs.microsoft.com/en-us/azure/jenkins/install-jenkins-solution-template\"" rel=\""nofollow noreferrer\"">Create a Jenkins server on an Azure Linux VM from the Azure portal</a>.</p>  <p>So I ran the command <code>ssh -L 127.0.0.1:8080:localhost:8080 jenkinsadmin@jenkins2517454.eastus.cloudapp.azure.com </code> (changed the username and dns name to my own) on my linux vm and it seems fine (no errors).</p>  <p>Now whenever I try to connect from my own computer (not on azure) on port 8080 I get on the linux vm the following message: <code>channel 2: open failed: administratively prohibited: open failed</code> and It doesn't let me log in into Jenkins.</p>  <p>How can it be solved?</p>  <p>Thank you</p>""",azure-virtual-machine
57272318,"Terraform Azure run bash script on VM <p>I'm trying to run a bash script on an Azure VM after deploying it with Terraform. I've tried different approaches but none of them have worked. With \custom_data\""  I assumed that the file will be uploaded and executed  however I'm not even seeing the file inside the VM. </p>  <p>I've also looked at \""azurerm_virtual_machine_extension\""  but this does not give me the option to upload the file  only to execute commands or download from remote location (can't use fileUris due to requirements): </p>  <pre><code>resource \""azurerm_virtual_machine_extension\"" \""test\"" {   name                 = \""hostname\""   location             = \""${azurerm_resource_group.test.location}\""   resource_group_name  = \""${azurerm_resource_group.test.name}\""   virtual_machine_name = \""${azurerm_virtual_machine.test.name}\""   publisher            = \""Microsoft.Azure.Extensions\""   type                 = \""CustomScript\""   type_handler_version = \""2.0\""    settings = &lt;&lt;SETTINGS     {         \""commandToExecute\"": \""sh my_script.sh\""     } SETTINGS    tags = {     environment = \""Production\""   } } </code></pre>  <pre><code>resource \""azurerm_virtual_machine\"" \""middleware_vm\"" {     name                  = \""${var.middleware_vm}\""     location              = \""${var.location}\""     resource_group_name   = \""${azurerm_resource_group.middleware.name}\""     network_interface_ids = [\""${azurerm_network_interface.middleware.id}\""]     vm_size               = \""Standard_DS4_v2\""              storage_os_disk {         name              = \""centos_os_disk\""         caching           = \""ReadWrite\""         create_option     = \""FromImage\""         managed_disk_type = \""Premium_LRS\""     }      storage_data_disk {         name                 = \""managed_backup_disk\""         create_option        = \""Empty\""         caching              = \""ReadWrite\""         disk_size_gb         = \""256\""           managed_disk_type    = \""Premium_LRS\""         lun                  = 0     }      storage_image_reference {         publisher = \""OpenLogic\""         offer     = \""CentOS\""         sku       = \""7.5\""         version   = \""latest\""     }      os_profile {         computer_name  = \""${var.middleware_vm}\""         admin_username = \""middlewareadmin\""         custom_data    = \""${file(\""scripts/middleware_disk.sh\"")}\""   } </code></pre>""",azure-virtual-machine
52928995,Monitor Windows Events (e.g. MSSQLServer) in Azure? <p>I searched for about one week for the oppurtunity to monitor different windows events  for example the SQL-event(or service) in AzureRM virtual machines. I tried it with different LogAnalytics queries  Runbooks  Powershell scripts to connect to the vm  etc. But everything I tried doesn't work.</p>  <p>Do you have any suggestions?</p>  <p>The solution should inform me  when a windows service stopped.</p>  <p>Best regards!</p>,azure-virtual-machine
23744500,"Downloading encrypted file from Window Azure storage <p>I have created a MVC WebRole Window Azure application where i upload encrypted files to Azure blob storage using SymmetricAlgorithm (Rijndael) like this</p>  <p>Controler>Action is</p>  <pre><code>[HttpPost] public ActionResult UploadImage_post(HttpPostedFileBase fileBase) {     if (fileBase.ContentLength &gt; 0)     {        // Retrieve a reference to a container         Microsoft.WindowsAzure.StorageClient.CloudBlobContainer blobContainer =               _myBlobStorageService.GetCloudBlobContainer();         Microsoft.WindowsAzure.StorageClient.CloudBlob blob =                 blobContainer.GetBlobReference(fileBase.FileName);        using (BlobStream blobStream = blob.OpenWrite())        {              string encryptionKey = //somekey;              byte[] file = new byte[fileBase.ContentLength];              EncDecAlgo.EncryptBlobFile(file  blobStream  encryptionKey);        }     } }  public void EncryptBlobFile(byte[] file  BlobStream bs  string key)     {         PasswordDeriveBytes pdb = new PasswordDeriveBytes(key              new byte[] {0x49  0x76  0x61  0x6e  0x20  0x4d           0x65  0x64  0x76  0x65  0x64  0x65  0x76});         Rijndael alg = Rijndael.Create();          alg.Key = pdb.GetBytes(32);         alg.IV = pdb.GetBytes(16);          CryptoStream cs = new CryptoStream(bs             alg.CreateEncryptor()  CryptoStreamMode.Write);          foreach (var data in file)         {             cs.WriteByte((byte)data);         }          cs.Close();         bs.Close();     } </code></pre>  <p>The above File encryption is working fine.</p>  <p>For Downloading code is</p>  <pre><code> public ActionResult DownloadFile(string filename)     {         // Retrieve reference to a previously created container.         Microsoft.WindowsAzure.StorageClient.CloudBlobContainer blobContainer =          _myBlobStorageService.GetCloudBlobContainer();          Microsoft.WindowsAzure.StorageClient.CloudBlob blob =             blobContainer.GetBlobReference(filename);         blob.FetchAttributes();         string encryptionKey = //same key used in encryption;         using (BlobStream blobStream = blob.OpenRead())         {             EncDecAlgo.DecryptBlobFile(blobStream  encryptionKey  filename);         }     }      public static void DecryptBlobFile(BlobStream bs  string key  string filePath)     {         try         {             PasswordDeriveBytes pdb = new PasswordDeriveBytes(key                  new byte[] {0x49  0x76  0x61  0x6e  0x20  0x4d  0x65           0x64  0x76  0x65  0x64  0x65  0x76});          Rijndael alg = Rijndael.Create();          alg.Key = pdb.GetBytes(32);         alg.IV =  pdb.GetBytes(16);          CryptoStream cs = new CryptoStream(bs              alg.CreateDecryptor()  CryptoStreamMode.Read);          // Decrypt &amp; Download Here         System.Web.HttpContext.Current.Response.AddHeader(\Content-Disposition\""  \""attachment; filename=\"" + Path.GetFileName(filePath));         System.Web.HttpContext.Current.Response.ContentType = \""application/\"" + Path.GetExtension(filePath).Replace(\"".\""  \""\"");           int data;         while ((data = cs.ReadByte()) != -1)         {             if (data != 0)             {             }             System.Web.HttpContext.Current.Response.OutputStream.WriteByte((byte)data);             System.Web.HttpContext.Current.Response.Flush();          }         cs.Close();         bs.Close();         }         catch         {         }     } </code></pre>  <p>On downloading get following error</p>  <pre><code>Server cannot set content type after HTTP headers have been sent. </code></pre>  <p>Please suggest some solution.</p>""",azure-storage
41853307,"using NUnit 2 and 3 in the same solution <p>I have 2 test projects in my solution. One is using NUnit version 2 (integration + SpecsFor) and another version 3.(Unit tests)</p>  <p>Running locally this works fine but when I execute the tests as part of a build on TFS I get an error message even though all tests passes. I read <a href=\https://stackoverflow.com/questions/35191374/nunit-tests-throwing-exception-only-when-run-as-part-of-tfs-msbuild-process#35193783\"">here</a> this occurring because VSTestAdapter2 cant run the v3 ones. </p>  <p>Is it not possible to run both version 2 and 3 in the TFS build? </p>""",azure-devops
49140572,"Access container started at Docker Compose step from Hosted Linux Agent on Azure VSTS <p>I am using VSTS build step Docker Compose v 0.* on Hosted Linux Agent. Here is my docker-compose:</p>  <pre><code>version: '3.0'  services:   storage:     image: blobstorageemulator:1.1     ports:       - \10000:10000\""   server:     build: .     environment:       - ENV=--tests     volumes:       - /var/run/docker.sock:/var/run/docker.sock     ports:       - \""8080:8080\""     depends_on:       - storage </code></pre>  <p>I use run services command. So basically I am running 2 Linux containers inside another Linux container (Build Agent). I was able to connect these containers to each other (server uses storage through connection string  which contains <code>storage</code> as a host - <code>http://storage:10000/devstoreaccount1</code>). Question: how to get access to the <code>server</code> from the build agent container? When I do <code>curl http://localhost:8080</code> on the next step it returns <code>Failed to connect to localhost port 8080: Connection refused.</code> PS Locally I run docker compose and can easily access my exposed port from host OS (I have VirtualBox with Ubuntu 17.10)</p>  <p>UPDATE: I tried using <code>docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' server-container-name</code> to get the IP address of the container running my server app and curl this IP  but I am getting connection timed out now.</p>""",azure-devops
53364267,"What is the VSTS Link Settings feature? <p>I am talking about this:</p>  <p><a href=\https://i.stack.imgur.com/hgg1s.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/hgg1s.png\"" alt=\""enter image description here\""></a></p>  <p>The documentation I found is here - <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/parameters?view=vsts\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/process/parameters?view=vsts</a>  but I must be plain stupid  because I do not understand one bit of it.</p>  <p>I do not know why it is so hard  but I cannot find anything meaningful on the web.</p>  <p>We have an on-premises TFS.</p>""",azure-devops
44182695,"How to auto-generate deploy.cmd in new Azure CLI? <p>I'm following <a href=\https://docs.microsoft.com/en-us/azure/app-service-web/web-sites-python-configure\"" rel=\""noreferrer\"">this guide</a> to create a web app with a custom <code>deploy.cmd</code> file. The article suggests that I can get a copy of the current <code>deploy.cmd</code> file (which I'll then modify) using the following command:</p>  <p><code>azure site deploymentscript --python</code></p>  <p>Unfortunately  when I install the Azure CLI using the MSI linked in the article  there is no <code>azure</code> binary on my path. I do have <code>az</code> -- is this a newer version of the same CLI? -- but I can't find an equivalent deployment script generation command for that executable.</p>  <p>I found a <code>deploy.cmd</code> file using Kudu (under <code>D:\\home\\site\\deployments\\tools</code>) but am not sure if that's the appropriate file to use. Can anyone suggest the right Azure CLI command for deployment script generation  or confirm that the <code>deploy.cmd</code> file I found is the right one to modify? Thanks in advance!</p>""",azure-web-app-service
52722373,Create Database and Collection on Cosmos Db (SQL API) inside AzureDevOpps (VSTS) <p>We have a business requirement where we have to create the Database and collection(s) as part of our CD step inside AzureDevOps. As far as my research shows this is not possible to do via ARM. </p>  <p>A support ticket to MS confirms this is not possible in ARM and has to be done inside your application. As mentioned a business requirement prevents us to do so.</p>  <p>The basic options are programmatically or the REST API of Cosmos Db.</p>,azure-devops
52990478,Web and Application tier on Azure Web apps <p>We have a 3 tier .Net application application that we want to migrate into cloud in 'cloud native'. Any reference architecture that can be use.</p>  <p>Also  will web and application tier be deployed as a separate web apps or application/API will be on some different app type within same VNet?</p>,azure-web-app-service
16153408,How can I view how many rows I have in each table in Windows Azure Table Storage? <p>Maybe I overlooked this in the Windows Azure Portal  but I can't find how many rows I currently have per table.  </p>  <p>If I query for it  I assume a transaction cost will be incurred.  Is there a way to freely see how many records there are?  </p>,azure-storage
47471822,How to build and deploy Azure Cloud Service with multiple configurations in VSTS Release management? <p>We are using <em>Team Services</em> to maintain our web projects and <em>Azure</em> for hosting. At now  there are several <em>Web Roles</em> (asp mvc) and <em>Worker Roles</em> which is being hosted as <em>Cloud Services</em>. We are going to setup <em>Continuous Integration and Delivery</em> for them.</p>  <p>As you know  <em>Team Services Build Definitions</em> suggest to use <em>Azure Cloud Service Template</em> for building and <em>Azure Cloud Service Deployment Task</em> to deploy. Weâ€™ve tried it for single cloud service and it works. </p>  <p>In our case  there are web project (web role) and scheduler (worker role) as separate <em>Cloud Services</em> and they should be deployed simultaneously (in sequence)  let it be DEV environment. But we have much more environments: dev  qa  ta  demo  preview  production  etc. Furthermore  each of them has slightly different <em>web.config  ServiceDefinition.csdef and ServiceConfiguration.cscfg</em>. And it became much more complicated task than just deploy one <em>Cloud Service</em>.</p>  <p>Questions are:</p>  <ul> <li><p>Should we build dozens of <em>Cloud Service pachages</em> (artifacts) and later decide which of them deploy or not? Could you suggest how to do it in a proper way? (in most cases it will be only Dev environment and we will waste time and resources for building other artifacts). </p></li> <li><p>Will it be better to build one common artifact and later replace all configurations for specific environment? (Itâ€™s more complicated task because Cloud Service package zipped on several occasions with preconfigured ServiceDefinition and ServiceConfiguration)</p></li> <li>What is the best way to replace configuration tokens (web.config  serviceconfiguration  etc) in Deployment mode  or it should be done while projects is being built?</li> </ul>  <p>I would be grateful if you suggest any best practices.</p>,azure-devops
40939629,"Is there a syntax for relative paths to functions wwwroot? <p>I am doing this which works  but it seems a bit of a hack</p>  <pre><code>using (var stream = new FileStream(@\d:\\home\\site\\wwwroot\\shared\\...\""  FileMode.Open  FileAccess.Read)) </code></pre>  <p>Is there a better pattern to obtain the path of wwwroot?</p>""",azure-functions
57342518,"How to set input for Azure Function to fetch table row in Azure Store? <p>I'm using the Azure portal to create my Azure Functions for my game. Right now I've set op storage with a table that is named gamesTable.</p>  <p>I've then had an Azure Function that is an HTTP trigger called GetGame and the thought is it should provide an id of the game (earlier created) and this id is the partition key in the table.</p>  <p>However  I'm having some problems understanding what to do with the window I've pasted below. As the HTTP request comes to the function  the table should be an input  and the result of the HTTP request should be to return the table column \Data\"" for that row with that id.</p>  <p>My table entity:</p>  <pre><code>public class Game {     public string PartitionKey { get; set; }     public string RowKey { get; set; }     public string Data { get; set; } } </code></pre>  <p>The documentation states that I have to provide partition key <strong>and</strong> row key. The request does not know about the row key. It should work with the query filter then and only take one. But how does that work? Query filter = 'PartitionKey eq header.partkey'? There header.partkey is a header in my request? Does anyone know how to set the context to the Query filter?</p>  <p><a href=\""https://i.stack.imgur.com/peNgu.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/peNgu.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
38851960,"Azure Template parameter \password\"" encryption <p>Is there a way to encrypt the VM useraccount password passed during Azure  provisioning?</p>  <p>As of now  we need to pass the password in plain text for the password to get set correctly when provisioning the VM  which is security issue.</p>  <p>I need to know is there is some Azure API available for password encryption.</p>""",azure-virtual-machine
41954515,Use Azure Function of (HttpTrigger â€“ C#) in Add Azure Logic App <p>I am writing an Azure function (HttpTrigger â€“ C#) that contains some statements that insert into Azure SQL Server. I followed this tutorial.</p>  <p>I want to use it in Azure Logic App. But it does not allow to add this type of function as an action.  Azure Logic App allows to add only those functions that are or Generic Webhook type. But Database storing support is available in (HttpTrigger â€“ C#) type functions. Is there a way to call (HttpTrigger â€“ C#) from another function that is already added in Azure Logic App. </p>  <p>Is there another better way to achieve it ?</p>,azure-functions
33304117,"Sysytem.EntryPointNotFoundException in Microsoft.Windows.Azurestorage.dll version 6.0.0 <p>I am using <code>Microsoft.WindowsAzure.Storage.dll</code> version 6.0.0 for working with Azure table storage. While adding a new entry in the table  I am getting following error.</p>  <p>Line of code throwing error:</p>  <pre><code>var operation = TableOperation.InsertOrReplace(entity); </code></pre>  <p><code>await this.CloudTable.ExecuteAsync(operation).ConfigureAwait(false);</code> -> // Throws error</p>  <p>where entity is of type TableEntity</p>  <p>I have referenced following assemblies:</p>  <pre><code>&lt;package id=\Microsoft.Azure.KeyVault.Core\"" version=\""1.0.0\"" targetFramework=\""net451\"" /&gt; &lt;package id=\""Microsoft.Data.Edm\"" version=\""5.6.4\"" targetFramework=\""net451\"" /&gt; &lt;package id=\""Microsoft.Data.OData\"" version=\""5.6.4\"" targetFramework=\""net451\"" /&gt; &lt;package id=\""Microsoft.Data.Services.Client\"" version=\""5.6.4\"" targetFramework=\""net451\"" /&gt; &lt;package id=\""Newtonsoft.Json\"" version=\""6.0.8\"" targetFramework=\""net45\"" /&gt; &lt;package id=\""System.Spatial\"" version=\""5.6.4\"" targetFramework=\""net451\"" /&gt; &lt;package id=\""WindowsAzure.Storage\"" version=\""6.0.0\"" targetFramework=\""net451\"" /&gt; </code></pre>  <p>Note: The code execute fine when run on my local machine  but throws above exception when run on a different environment which we don't own. (Different set of machines hosted somewhere else  and also we don't have access to these machines)</p>  <p><strong>Error:</strong></p>  <blockquote>   <p>Error: System.EntryPointNotFoundException: Entry point was not   found.#R##N#   at   Microsoft.WindowsAzure.Storage.Table.ITableEntity.get_PartitionKey()#R##N#   at   Microsoft.WindowsAzure.Storage.Table.TableOperation.GenerateCMDForOperation(CloudTableClient   client  CloudTable table  TableRequestOptions modifiedOptions)#R##N#<br>   at   Microsoft.WindowsAzure.Storage.Table.TableOperation.BeginExecute(CloudTableClient   client  CloudTable table  TableRequestOptions requestOptions    OperationContext operationContext  AsyncCallback callback  Object   state)#R##N#   at   Microsoft.WindowsAzure.Storage.Table.CloudTable.BeginExecute(TableOperation   operation  TableRequestOptions requestOptions  OperationContext   operationContext  AsyncCallback callback  Object state)#R##N#   at   Microsoft.WindowsAzure.Storage.Table.CloudTable.BeginExecute(TableOperation   operation  AsyncCallback callback  Object state)#R##N#   at   Microsoft.WindowsAzure.Storage.Core.Util.AsyncExtensions.TaskFromApm[T1 TResult](Func 4   beginMethod  Func 2 endMethod  T1 arg1  CancellationToken   cancellationToken)#R##N#   at   Microsoft.WindowsAzure.Storage.Table.CloudTable.ExecuteAsync(TableOperation   operation  CancellationToken cancellationToken)#R##N#   at   Microsoft.WindowsAzure.Storage.Table.CloudTable.ExecuteAsync(TableOperation   operation)#R##N#   at   Microsoft.OnlinePublishing.Retry.TaskRetryer 2.DoAction()#R##N#--- End   of stack trace from previous location where exception was thrown   ---#R##N#   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task   task)#R##N#   at   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task   task)#R##N#   at   System.Runtime.CompilerServices.ConfiguredTaskAwaitable 1.ConfiguredTaskAwaiter.GetResult()#R##N#   at   Microsoft.OnlinePublishing.Ingestion.Common.Cache.CloudTableManager.d__6 1.MoveNext()</p> </blockquote>""",azure-storage
38847544,How can I restrict virtual machine sizes with Azure RBAC? <p>As an administrator  I need to limit the sized of VMs my end-users can provision through the Azure portal. I'm looking for something similar to what I can do with AWS IAM  make sure that users can only provision certain sizes of VMs.</p>,azure-virtual-machine
43610318,"Azure web app automatically redirect from Http to Https <p>I have a website on Azure and I have configured it with the custom domain.Website always redirects from http to https so getting error of not secure in browser as below..</p>  <p><a href=\https://i.stack.imgur.com/IwZMG.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/IwZMG.jpg\"" alt=\""enter image description here\""></a></p>  <p>I don't want to redirect it to https.What is the solution and what is the reason that it redirects to https ?</p>  <p>On azure in web app overview I get URL with Http :</p>  <p><a href=\""https://i.stack.imgur.com/F6Ge0.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/F6Ge0.jpg\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
56482234,Deployed Azure python function  can not run because 'azure.storage' module could not be found <p>After deploying my Python Function App  when I try to run it on Azure cloud  it fails with  the following error: How can I install azure-storage on the machine running the app service? Please help.</p>  <p>import azure.functions as func import datetime</p>  <p>import os  uuid  sys from azure.storage.blob import BlockBlobService  PublicAccess ..... ......</p>,azure-functions
50681549,"Is it possible to open port in Azure Linux Web App <p>I have a framework which connects to Virtual Machine through the specific port. But I want to make WebApp Linux on Azure with this code.</p>  <p>I used image docker file where I exposed necessary port. If itâ€™s enough to open the port?</p>  <p><a href=\https://i.stack.imgur.com/B6nBt.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/B6nBt.jpg\"" alt=\""enter image description here\""></a></p>  <p>By the way in Azure portal tab Networking is always grey.</p>""",azure-web-app-service
39620781,azure - How to connect to socket server program running on virtual machine <p>I have a socket based game server running on a virtual machine in Azure. And Azure provides IP(public) and port(public) which is used for remote control.</p>  <p>I tried to connect to the server program with the IP and port. The client socket is connected but apparently not to the server program. client does not receive any and the server program told me there was nothing.</p>  <p>How do I connect to a server program running on Azure's virtual machine?</p>  <p>(the server program is a console project made by Visual Studio.)</p>,azure-virtual-machine
45904799,"Can't find Azure Functions when setting up new project in VS 2017 <p>I've recently started to learn Azure Functions. I set up some on the portal  but now I want to develop them in Visual Studio.</p>  <p>I have VS 2017 in version 15.3.2 and I also installed Azure development workload. I've seen on tutorials that I'm supposed to have \Azure Functions\"" in the Cloud tab when adding new project - but it isn't there. I checked this on my personal and work computer.</p>  <p>I've found \""Azure Functions and Web Jobs Tools\"" add-on on VS Gallery. It adds \""Azure Functions\"" options  but it isn't working as I wished. I don't have dedicated forms for adding new functions and things like that.</p>  <p>Is there any bug in this addon? Do you know if I have to install something more?</p>""",azure-functions
57659799,"Unable to run time triggered function with CosmosDB Binding in Azure as SpringBoot App <p>Unable to Package the dummy app </p>  <pre><code>[INFO] Using 'UTF-8' encoding to copy filtered resources. [INFO] Copying 1 resource to D:\\MyFiles\\akarforma\\Downloads\\hello-spring-function-azure-master\\target\\azure-functions\\spring-mongtotimer [INFO] Copied successfully. [INFO] Step 7 of 7: Installing function extensions if needed Extensions command requires dotnet on your path. Please make sure to install dotnet (.NET Core SDK) for your system from https://www.microsoft.com/net/download [ERROR] [ERROR] Failed to install the Function extensions [INFO] --------------------------------------------------- </code></pre>  <p>And after publishing it into the Azure getting </p>  <p>Error:</p>  <pre><code>Function (spring-mongtotimer/hellodummy) Error: The binding type(s) 'cosmosDB' are not registered. Please ensure the type is correct and the binding extension is installed.         @FunctionName(\helloTimer\"")  public void execute(@TimerTrigger(name = \""timerInfo\""  schedule = \""*/1 * * * * *\"") String timerInfo @CosmosDBInput(name = \""documents\""  databaseName = \""db1\""  collectionName = \""col1\""  connectionStringSetting = \""dbStr\"") Optional&lt;String&gt;documents ExecutionContext context){ </code></pre>""",azure-functions
55658518,Azure Pipelines: How to provide app.config? <p>Currently I'm building a (pet) .NET project locally. The code is managed via Git. What's local is my <code>app.config</code> containing credentials in the <code>appSettings</code> section used in unit tests. I don't want to commit this.</p>  <p>Now I want to move to Azure Pipelines to set up automated builds. Of course I don't want to commit my <code>app.config</code> so currently it is missing and the build fails because of that.</p>  <p>How would I create the <code>app.config</code> (or something similar?) in Azure Pipelines?</p>,azure-devops
18225473,Do we have any options to collect storage service operation logs in Azure using Rest API <p>Through the Windows Azure management portal  we can check the storage service operation logs. Is there any way to access those logs using REST APIs in Azure?</p>  <p>Since I can't post the image: </p>  <p>The steps to operation logs ->in the azure portal -> management services -> operation logs(date range) -> list out the operation performed such as VM created/deleted</p>  <p>Are there any Azure APIs to capture these logs programmatically?</p>,azure-storage
57226356,"How to List all Blobs using Azure Storage Account SAS Token? <p>Using the Python <code>azure-storage</code> API I am expecting to be able to generate an Account SAS token which allows me to read and write blobs in any container in my storage account. </p>  <p>The generation of the SAS token goes without exception  but when I try to create a <code>BlockBlobService</code> using that SAS token and list some blobs for a given container  I get an <code>AuthorizationPermissionMismatch</code> error from Azure.</p>  <p>Am I understanding the concept of an Account SAS token correctly?</p>  <p>I have looked at a ton of documentation on Azure's \Getting Started\"" documentation for the Python Storage API  also I've looked through <a href=\""https://azure-storage.readthedocs.io/ref/azure.storage.blob.sharedaccesssignature.html\"" rel=\""nofollow noreferrer\"">https://azure-storage.readthedocs.io/ref/azure.storage.blob.sharedaccesssignature.html</a> quite a bit.</p>  <p>I have tried using <code>azure.storage.blob.BlockBlobService.generate_account_shared_access_signature()</code> with very permissive permissions and am still getting the exception.</p>  <p>I can confirm that <code>azure.storage.blob.BlockBlobService.generate_container_shared_access_signature()</code> does work fine  however my requirement is to generate a SAS Token irrespective of then container.</p>  <pre class=\""lang-py prettyprint-override\""><code>from azure.storage.blob import BlockBlobService from azure.storage.models import AccountPermissions  ResourceTypes  bbs = BlockBlobService(\""myaccountname\""  \""myaccountkey\"")  sas_token = bbs.generate_account_shared_access_signature(                     ResourceTypes.CONTAINER + ResourceTypes.OBJECT + ResourceTypes.SERVICE                      AccountPermissions.READ + AccountPermissions.WRITE + AccountPermissions.LIST + AccountPermissions.CREATE                      datetime.utcnow() + timedelta(hours=1)                     )  BlockBlobService(account_name=\""myaccountname\""  sas_token=sas_token).list_blobs(\""containername\"") </code></pre>  <pre><code>azure.common.AzureHttpError: This request is not authorized to perform this operation using this permission. &lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt;&lt;Error&gt;&lt;Code&gt;AuthorizationPermissionMismatch&lt;/Code&gt;&lt;Message&gt;This request is not authorized to perform this operation using this permission. RequestId:6a06b32e-f01e-005a-44e7-430c8b000000 Time:2019-07-26T19:22:02.7337249Z&lt;/Message&gt;&lt;/Error&gt; </code></pre>  <p>I expected to be able to call <code>list_blobs()</code> here no problem. How can I accomplish this without having to generate a SAS Token container by container?</p>""",azure-storage
52607482,Azure - Folders in 'Blobs storage' and Folders in 'File storage' <p>This may seem Naive  I understand that we can create folders in a blob  and these folders are still stored in a container. we can still do everything on these 'folders contained in blobs' that we typically do on folders in File storage.</p>  <p>We can still use these 'Folder/Directory structure in blob containers' just like we use 'Folder/Directory structure in File storage' than what is the significance of having a file storage?</p>  <p>I know there could be some places where File storage must be playing a significant role. I just want to know few of those use-cases.</p>,azure-storage
56158097,How to point to specific commit on referenced repository for Azure Pipelines build <p>Our team uses an Azure DevOps Pipeline that runs based on the code in another repository. We have a yaml file written within our repository that references the other repository for our Azure DevOps Pipeline as follows:</p>  <pre><code>resources:   repositories:   - repository: e2e_fx     type: github     name: Azure/iot-sdks-e2e-fx     ref: refs/heads/master     endpoint: 'GitHub OAuth'  jobs: - template: vsts/templates/jobs-gate-c.yaml@e2e_fx </code></pre>  <p>Currently the yaml points to the head of master for the other repository  so if a new commit is added to that remote repository then it will be pointed to. I want to be able to reference a specific commit from the repository referenced. How can I do that?</p>  <p>For reference  I've already tried copying the specific commit I want to reference and pasting it where <code>refs/heads/master</code> is right now  but that gave an error.</p>,azure-devops
56852583,"Azure function can't connect to Azure SQL Database <p>I've created an Azure function that should connect to an Azure SQL database.</p>  <p>This function retrieves the connection string saved in the application config. This connection string is the one provided from Azure SQL.</p>  <p>Everything works fine on my PC  but I've deployed the function on Azure and it seems unable to connect to the SQL database (returning the common error \object reference not set...\"").</p>  <p>I've checked <code>possibleOutboundIpAddresses</code> in Azure function resources and I've allowed them on the Azure SQL firewall.</p>  <p>Also  my SQL database is in a Azure VNet with a storage.</p>  <p>Any idea?</p>""",azure-functions
52833645,"Azure Function not logging to Application Insights <p>I have an Azure Functions project that was deployed to a Function App for dev/test and was successfully writing log messages to Application Insights. I published the same project to a new Function App  in the same Azure subscription and now neither App logs anything to Application Insights.</p>  <p>The project was deployed using Visual Studio (15.8.7 with Azure Functions and Web Jobs Tools 15.9.02009.0).</p>  <p>I tried adding a logger entry to host.json to explicitly set the Function category log level to information.</p>  <p>The Azure Functions and Web Jobs Tools extension is up to date in Visual Studio.</p>  <p>I also tried deleting the APPINSIGHTS_INSTRUMENTATIONKEY application setting  and restarting the App  so that then when I clicked on the Monitor tab for one of the functions it went through the wizard to configure Application Insights. At the end of that though  it displayed the message \your app is offline or the application insights sdk needs updating\"".</p>  <p>Any ideas what could be wrong?</p>""",azure-functions
53723836,"azure cli vm create tags <p>When creating VM via az cli (bash) with a list of tags.</p>  <p>First set this variable:<br> <code>tags='env=qa servertype=frontend Distinct=qa-frontend25 CI=Yes DataDog:True'</code></p>  <p>However when running the below command in bash shell<br> <code> az vm create ... --tags \${tags}\"" </code></p>  <p>It creates one long tag that has key <code>env</code> and value <code>qa servertype=frontend Distinct=qa-frontend25 CI=Yes DataDog=True</code> </p>  <p>From Azure CLI <a href=\""https://docs.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest#az-vm-create\"" rel=\""nofollow noreferrer\"">documentation</a>  </p>  <p><code>--tags      Space-separated tags in 'key[=value]' format.</code></p>  <p>What am  missing here?</p>""",azure-virtual-machine
34708731,"Azure: Moving an App Service to another existing App Service Plan <p>I'm attempting to move an App Service from one service plan to another.  When I use the portal to do so  the other App Service plan is not displaying. </p>  <p>Both App Services are in the same Location and Resource Group. The two App Services Plans are in the same location and have the same pricing tier.</p>  <p>I use the \Change App Service Plan\"" option for the web app.  The only App Service Plan that is displayed is the current one. There is also a \""Create New\"" option.</p>  <p>So  in summary: 1) Why is the other App Service Plan not able to be selected. 2) How can I move the App Service (Web App) to the other App Service Plan.</p>""",azure-web-app-service
9982738,"How would Azure storage be billed? <p>According to the Azure homepage  it says:</p>  <p>[Storage  measured in GB] (http://www.windowsazure.com/en-us/pricing/details/)</p>  <p>Storage is billed in units of the average daily amount of data stored (in GB) over a monthly period. For example  if you consistently utilized 10 GB of storage for the first half of the month and none for the second half of the month  you would be billed for your average usage of 5 GB of storage.</p>  <p>I don't understand clearly about the term  \utilization\"" here. Let's say I have 10GB data in my Azure table storage  and only 1 GB (out of 10GB) data is actually \""read\"" during this month. In this case  will I be paying based on the storage space I've been using (i.e.  10GB) or based on the data I have actually read (i.e.  1GB) ?</p>""",azure-storage
50739869,"Web App is not loading after deploying <p>I have a working app service named \matanwebserver\"" over a subscription in Azure. This is a website that I am working on. I work with Visual Studio.</p>  <p>Now I created another Web App on the same subscription that I will use as an integration site so I can test my code before publishing to the production site. The name of the new Web App is \""matanwebservertest\"". After publishing my project from Visual Studio to the new Web App  when I enter it's URL it seems like nothing happened  but it writes \""Your App Service app is up and running\"".</p>  <p>What am I doing wrong?</p>  <p><strong>Added some screenshots for a better understanding of the issue</strong></p>  <ol> <li>In Visual Studio I do right click on the web app which is called \""MatanWebServer\"" and choose \""publish\"". Then I choose the new web app that I just created on Azure portal which called \""matanwebserertest\""  and publish successfully.</li> </ol>  <p><a href=\""https://i.stack.imgur.com/sTlvc.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/sTlvc.jpg\"" alt=\""enter image description here\""></a></p>  <ol start=\""2\""> <li>This is the original (production) website. which its address is <a href=\""http://matanwebserver.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://matanwebserver.azurewebsites.net</a></li> </ol>  <p><a href=\""https://i.stack.imgur.com/wXRpR.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/wXRpR.png\"" alt=\""enter image description here\""></a></p>  <ol start=\""3\""> <li>After publish to the matanwebservertest web app  I expect to see a \""copy\"" of the original site  but it seems like nothing is there.</li> </ol>  <p><a href=\""https://i.stack.imgur.com/Lrwcn.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Lrwcn.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
50399463,Publish app containing virtual directory to Azure app service <p>I have an app that's structured like this:</p>  <pre><code>app\ &lt;-- not exposed through IIS  -&gt; Config\ &lt;-- Contains config for IIS application  -&gt; Shared\ &lt;-- Contains binaries for IIS application  -&gt; Transform\ &lt;-- Config  etc  -&gt; Web\  &lt;--- IIS application directory </code></pre>  <p>I don't want to have to restructure the entire thing so that everything outside Web\ is contained within it and referenced that way. However  I can't get visual studio to publish to my app service in such a way that Web\ is the IIS application directory and everything else is published above it.</p>  <p>I've tried a lot of different ways to set the Virtual Applications and Directories for the app service but none of them are working. How can I publish to a parent of the IIS application directory?</p>,azure-web-app-service
43764108,Microsoft.SqlServer.Types: Are native libries for SQL Server preinstalled on Azure? <p>I just upgraded my app to use the latest Microsoft.SqlServer.Types package v14 from v13. This resulted in an well-documented runtime error. The reason here would be missing native libraries:</p>  <pre><code>Spatial types and functions are not available for this provider because the assembly 'Microsoft.SqlServer.Types' version 10 or higher could not be found </code></pre>  <p>The Nuget package also contains the native DLLs that were missing  so I could theoretically copy them to my bin folder and load them through my code  but:</p>  <ul> <li>I didn't have to do that with my v13 binaries</li> <li>When I deployed the updated project to Azure  it ran just fine.</li> </ul>  <p>My current assumption would be that I got the v13 binaries with my local SQL install  and on Azure  those binaries (both v13 / v14) are preinstalled.</p>  <p>However  when googling a bit about the issue  most developers have the opposite problem of things not working on Azure due to the missing libs  so I wonder whether not going the manual route might be dangerous with regards to Azure deployments. If anybody had some insight here  that would be awesome!</p>,azure-web-app-service
50514840,Azure virtual machine image disables AutoLogin when deployed <p>I have created an image from a virtual machine with AutoLogin enabled and programs set to run on startup  when I deploy virtual machines from the image it will only sign in when using RDP. I had the same thing setup with Amazon Web Services using an AMI. </p>  <p>How would I create a disk image on Azure preconfigured to sign in and run a program when I deploy it automatically?</p>,azure-virtual-machine
